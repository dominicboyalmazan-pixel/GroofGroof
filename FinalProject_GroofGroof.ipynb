{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi4p88AUpNWC"
      },
      "source": [
        "# **DATA PREPROCESSING PHASE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvmIOOoRAeVN"
      },
      "source": [
        "# **1. Importing Required Libraries**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCk-kMFGuO4h"
      },
      "source": [
        "**Function Description:**\n",
        "This code sets up all the tools needed for data preprocessing, text cleaning, and machine learning. It also includes libraries for data visualization, oversampling, and natural language processing to prepare text data for model training.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The first group of imports (pandas, numpy, matplotlib, seaborn) allows data manipulation and visualization. The next group (re, random, imblearn, scipy, wordcloud) helps in text handling, balancing datasets, and generating visual word patterns.\n",
        "The nltk section downloads and loads tools for tokenizing text, removing stopwords, and applying stemming or lemmatization. The scikit-learn and xgboost imports bring in various models, feature extraction tools, and metrics for evaluation. Finally, the warnings library is used to hide unnecessary warning messages during execution.\n",
        "\n",
        "**Inputs:**\n",
        "No inputs are provided yet. This section only prepares the libraries and tools that will be used in later parts of the program.\n",
        "\n",
        "**Outputs:**\n",
        "There are no outputs in this section since it only sets up the environment by importing and downloading the necessary modules.\n",
        "\n",
        "**Code Flow:**\n",
        "When this code runs, Python imports all required libraries and downloads NLTK resources. Once completed, the notebook will be ready to handle data preprocessing, feature extraction, and model training in the following cells.\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step acts as the foundation for the entire preprocessing process. By loading all necessary packages early, later steps like cleaning, transforming, and modeling data can run smoothly and efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Z0LQHf6AbT8",
        "outputId": "849f81dd-a81e-4218-d89c-a7f0f4c9789f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "# Data manipulation and visualization\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "# Text processing and utility libraries\n",
        "import re\n",
        "import random\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from scipy.sparse import hstack\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Natural Language Toolkit (NLTK)\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download the required tokenizer, stopword, and lemmatizer data\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Machine learning and preprocessing\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.utils import resample\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnHlQGXdApmf"
      },
      "source": [
        "# **2. Reading and Understanding our Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3Cp5YB2urbO"
      },
      "source": [
        "**Function Description:**\n",
        "This code loads the dataset named **Combined Data.csv** into a pandas DataFrame so it can be used for analysis and preprocessing.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The command `pd.read_csv('/content/Combined Data.csv', index_col=0)` uses pandas to read a CSV file located at the given path. The parameter `index_col=0` tells pandas to use the first column of the CSV file as the DataFrame’s index instead of creating a new one automatically.\n",
        "\n",
        "**Inputs:**\n",
        "The input is the file **Combined Data.csv**, which contains the dataset to be analyzed.\n",
        "\n",
        "**Outputs:**\n",
        "The output is a pandas DataFrame named **df**, which stores all the data from the CSV file in a structured, table-like format.\n",
        "\n",
        "**Code Flow:**\n",
        "When this code runs, pandas reads the CSV file, assigns the first column as the index, and loads the data into memory as a DataFrame. This allows the next steps, such as cleaning, transforming, and analyzing the data, to begin.\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step marks the start of working with the dataset. Loading it properly ensures that all future preprocessing and analysis tasks can be performed efficiently on the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEbHsffgArTU"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/Combined Data.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Xh6tUjMu39o"
      },
      "source": [
        "**Function Description:**\n",
        "This code checks and displays how many samples belong to each mental health status category before any data filtering or preprocessing is applied. It helps in understanding the distribution of sentiments or mental health conditions in the dataset.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The command df['status'].value_counts() counts how many times each unique value appears in the status column of the DataFrame. The print() statements display both a label (“Before filtering:”) and the resulting counts for clarity.\n",
        "\n",
        "**Inputs:**\n",
        "The input comes from the status column in the df DataFrame, which contains labels such as Normal, Depression, Anxiety, and other mental health conditions.\n",
        "\n",
        "**Outputs:**\n",
        "The output lists the number of records for each category.\n",
        "For example:\n",
        "\n",
        "*   Normal: 16,351\n",
        "*   Depression: 15,404\n",
        "*   Suicidal: 10,653\n",
        "*   Anxiety: 3,888\n",
        "*   Bipolar: 2,877\n",
        "*   Stress: 2,669\n",
        "*   Personality disorder: 1,201\n",
        "\n",
        "**Code Flow:**\n",
        "When this code runs, pandas counts the occurrences of each label in the status column and prints the results in descending order based on frequency.\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step provides an overview of how balanced or imbalanced the dataset is. Since some categories have far more samples than others, later steps like oversampling or class balancing may be needed to improve model training performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09DrwYedJazo",
        "outputId": "7885e339-e1c8-4d4f-91f9-f3a1717342da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before filtering:\n",
            "status\n",
            "Normal                  16351\n",
            "Depression              15404\n",
            "Suicidal                10653\n",
            "Anxiety                  3888\n",
            "Bipolar                  2877\n",
            "Stress                   2669\n",
            "Personality disorder     1201\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Before filtering:\")\n",
        "print(df['status'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWy0lxefwKic"
      },
      "source": [
        "**Function Description:**\n",
        "This code filters the dataset to keep only records labeled as Normal or Suicidal. The goal is to simplify the analysis by focusing on identifying whether a comment shows suicidal tendencies or is considered normal.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The expression df['status'].isin(['Normal', 'Suicidal']) checks each value in the status column to see if it matches either \"Normal\" or \"Suicidal\". Only the rows that meet this condition are kept. The function reset_index(drop=True) resets the row numbering so that the DataFrame looks clean and organized after filtering.\n",
        "\n",
        "**Inputs:**\n",
        "The input is the status column from the DataFrame, which contains several mental health categories.\n",
        "\n",
        "**Outputs:**\n",
        "The output is a filtered DataFrame named df that includes only the Normal and Suicidal categories.\n",
        "\n",
        "**Code Flow:**\n",
        "When the code runs, pandas examines each row in the status column. Rows labeled Normal or Suicidal are kept, and all others are removed. Afterward, the index is reset to ensure that the row numbers start from zero again.\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step turns the problem into a binary classification task. By focusing only on Normal and Suicidal records, the analysis can better determine whether a given comment indicates suicidal intent or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42Qv-7xrJe2D"
      },
      "outputs": [],
      "source": [
        "# Keep only 'Normal' and 'Suicidal' records\n",
        "df = df[df['status'].isin(['Normal', 'Suicidal'])].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU4eSy9ewSWw"
      },
      "source": [
        "**Function Description:**\n",
        "This code displays the number of records for each category after filtering the dataset. It helps confirm that only the Normal and Suicidal classes remain for further analysis.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The command df['status'].value_counts() counts how many records belong to each category in the status column. The print statement print(\"\\nAfter filtering:\") adds a blank line before the message for clearer output formatting.\n",
        "\n",
        "**Inputs:**\n",
        "The input is the filtered DataFrame df, which now contains only the Normal and Suicidal categories.\n",
        "\n",
        "**Outputs:**\n",
        "The output shows the number of remaining records in each category:\n",
        "\n",
        "*   Normal: 16,351\n",
        "*   Suicidal: 10,653\n",
        "\n",
        "**Code Flow:**\n",
        "When this code runs, pandas counts the occurrences of each label in the status column and prints them in descending order. The added print statement makes the output easier to read by separating it from the previous output.\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step verifies that the filtering process worked correctly. The dataset now contains only two categories, confirming that it is ready for binary sentiment analysis focused on identifying suicidal expressions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8WALNZtJkQ6",
        "outputId": "712d4598-4abe-4e04-a1ad-0d2d0d85c83e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After filtering:\n",
            "status\n",
            "Normal      16351\n",
            "Suicidal    10653\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"After filtering:\")\n",
        "print(df['status'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjOyjzoixR-M"
      },
      "source": [
        "**Function Description:**\n",
        "This code shows how many Normal and Suicidal records there are before and after balancing the dataset. It also makes both classes equal in number so the model will not favor one over the other.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The sns.countplot() command draws bar charts to show the number of records in each class. The resample() function is used to randomly reduce the larger group (Normal) so it has the same number of samples as the smaller group (Suicidal). The balanced data is then combined, shuffled, and reset to make it ready for training.\n",
        "\n",
        "**Inputs:**\n",
        "The input is the filtered DataFrame df that includes only Normal and Suicidal records.\n",
        "\n",
        "**Outputs:**\n",
        "The outputs include two charts and one printed result.\n",
        "\n",
        "1. A bar chart that shows the class distribution before balancing.\n",
        "2. A message saying “Balanced dataset created successfully.”\n",
        "3. A result showing that both Normal and Suicidal now have 10,653 records each.\n",
        "4. A second chart showing the balanced dataset.\n",
        "\n",
        "**Code Flow:**\n",
        "First, the code plots the unbalanced data. Then it separates Normal and Suicidal records, reduces the number of Normal samples to match Suicidal, and combines them again. After that, the data is shuffled, printed, and plotted again to confirm that the classes are now equal.\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step makes the dataset fair by having the same number of Normal and Suicidal samples. Balancing the data helps the model learn both types of comments equally and avoid bias during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        },
        "id": "FmyZIYSDLmEY",
        "outputId": "9f30bd4c-566a-40c6-c91e-03ece791c51f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced dataset created successfully.\n",
            "status\n",
            "Suicidal    10653\n",
            "Normal      10653\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Before balancing: visualize class distribution\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x='status', data=df, palette='pastel')\n",
        "plt.title(\"Class Distribution Before Balancing\")\n",
        "plt.xlabel(\"Status\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n",
        "# Balance the dataset using random undersampling\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Separate majority and minority classes\n",
        "df_normal = df[df['status'] == 'Normal']\n",
        "df_suicidal = df[df['status'] == 'Suicidal']\n",
        "\n",
        "# Downsample majority class (Normal) to match Suicidal\n",
        "df_normal_downsampled = resample(df_normal,\n",
        "                                 replace=False,\n",
        "                                 n_samples=len(df_suicidal),\n",
        "                                 random_state=42)\n",
        "\n",
        "# Combine balanced dataset\n",
        "df_balanced = pd.concat([df_normal_downsampled, df_suicidal])\n",
        "\n",
        "# Shuffle the balanced dataset\n",
        "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(\"Balanced dataset created successfully.\")\n",
        "print(df_balanced['status'].value_counts())\n",
        "\n",
        "# After balancing: visualize class distribution\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x='status', data=df_balanced, palette='pastel')\n",
        "plt.title(\"Class Distribution After Balancing\")\n",
        "plt.xlabel(\"Status\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qfk6dhe7xwT7"
      },
      "source": [
        "**Function Description:**\n",
        "This code shows the first few rows of the dataset to help you quickly check if the data looks correct after balancing.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The function df.head() displays the top five rows of the DataFrame by default. It helps confirm that the dataset was loaded or processed properly.\n",
        "\n",
        "**Inputs:**\n",
        "The input is the DataFrame df, which contains the data you are working with.\n",
        "\n",
        "**Outputs:**\n",
        "The output is a small preview of the first five rows of df, showing the column names and sample data.\n",
        "\n",
        "**Code Flow:**\n",
        "When this code runs, pandas prints a short table with the first five rows of the DataFrame. This helps you verify that the dataset looks complete and in the right format before continuing.\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step gives a quick look at the structure of the dataset, such as column names, values, and whether the data is clean and ready for the next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DALBlVtRAtRo",
        "outputId": "7cbd26f2-486f-478f-f843-10809ebd5b0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           statement  status\n",
              "0      Gr gr dreaming of ex crush to be my game, God  Normal\n",
              "1                                 wkwkwk what a joke  Normal\n",
              "2  Leaves are also standby in front of the PC ......  Normal\n",
              "3     Thank God even though it's just a ride through  Normal\n",
              "4  wedding teaser concept using the song day6 - o...  Normal"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6792c80-a799-4029-a7e0-6fd118a1b49a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Gr gr dreaming of ex crush to be my game, God</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wkwkwk what a joke</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Leaves are also standby in front of the PC ......</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Thank God even though it's just a ride through</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wedding teaser concept using the song day6 - o...</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6792c80-a799-4029-a7e0-6fd118a1b49a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d6792c80-a799-4029-a7e0-6fd118a1b49a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d6792c80-a799-4029-a7e0-6fd118a1b49a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a974f753-9f40-42b0-8a68-cebd44bd5e49\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a974f753-9f40-42b0-8a68-cebd44bd5e49')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a974f753-9f40-42b0-8a68-cebd44bd5e49 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 27004,\n  \"fields\": [\n    {\n      \"column\": \"statement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26683,\n        \"samples\": [\n          \"I have been here long enough and I am ready to leave now, I am not young so my dearh will not be a tragedy. I have had enough of my pathetic existence. I am thinking of going through with it next week, I wonder how long it takes to actually die from hanging... When do I get to die?\",\n          \"i honestly do not know how much longer i can go. I have attempted many times in the past by overdosing but sadly survived. one of the biggest reasons why I am still here is, bc i do not want my parents to have to bury me. i do not want to pass my pain onto others, but i really do not have much left in me. i have dreams &amp; goals, but they seem so impossible with depression draining me, &amp; suicide on my mind 24/7. I have been to the psych ward many times, tried many different medications, &amp; have seen therapists. my friends &amp; family are supportive, but they really do not understand. i just wish i was already gone. cannot keep going\",\n          \"in the photoshop\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Suicidal\",\n          \"Normal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mEpIkoKx8Aw"
      },
      "source": [
        "**Function Description:**\n",
        "This code shows a summary of the dataset’s numeric columns. It gives quick information about the overall structure and range of the data.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The command df.describe() calculates basic statistics such as count, mean, standard deviation, minimum, maximum, and quartiles (25%, 50%, 75%) for all numeric columns in the DataFrame.\n",
        "\n",
        "**Inputs:**\n",
        "The input is the DataFrame df, which contains the dataset.\n",
        "\n",
        "**Outputs:**\n",
        "The output is a table showing statistical details for each numeric column, including the number of values, their average, spread, and range.\n",
        "\n",
        "**Code Flow:**\n",
        "When this code runs, pandas scans all numeric columns in df and computes summary statistics for each one. It then displays the results in an easy-to-read table format.\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step helps check if the data has missing or unusual values. It also provides a quick understanding of how the numbers in the dataset are spread out before deeper analysis or model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "bSh8oSvoA2vq",
        "outputId": "ca54aa97-dc94-452e-8ebd-b22e83979519"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                statement  status\n",
              "count               26995   27004\n",
              "unique              26683       2\n",
              "top     what do you mean?  Normal\n",
              "freq                   22   16351"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d431f572-a39a-426e-a41d-75351db7a3b2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>26995</td>\n",
              "      <td>27004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>26683</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>what do you mean?</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>22</td>\n",
              "      <td>16351</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d431f572-a39a-426e-a41d-75351db7a3b2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d431f572-a39a-426e-a41d-75351db7a3b2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d431f572-a39a-426e-a41d-75351db7a3b2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f35a052f-3660-46b8-b318-6edffde5f8c6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f35a052f-3660-46b8-b318-6edffde5f8c6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f35a052f-3660-46b8-b318-6edffde5f8c6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"statement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          26683,\n          \"22\",\n          \"26995\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"status\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          \"16351\",\n          \"27004\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg2hPdiFyI8S"
      },
      "source": [
        "**Function Description:**\n",
        "This code gives a quick summary of the dataset, showing the column names, data types, and how many non-missing values each column has.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The command df.info() is a pandas function that prints information about the DataFrame, including the total number of rows, the number of non-null entries per column, the data type of each column, and the amount of memory the dataset uses.\n",
        "\n",
        "**Inputs:**\n",
        "The input is the DataFrame df, which contains the data being analyzed.\n",
        "\n",
        "**Outputs:**\n",
        "The output is a text summary that lists the columns, their data types, how many values each column has, and whether there are any missing entries.\n",
        "\n",
        "**Code Flow:**\n",
        "When this code runs, pandas checks the structure of the DataFrame and prints key details about it, allowing you to understand the data types and completeness of the dataset.\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step helps you verify that all columns have the correct data types and that no important columns have missing values before starting the preprocessing or modeling steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZXGNqeAA2ua",
        "outputId": "bc1ccdd4-ff0b-466e-e9f9-1ade6a820d2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27004 entries, 0 to 27003\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   statement  26995 non-null  object\n",
            " 1   status     27004 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 422.1+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxyvW5m-A7Br"
      },
      "source": [
        "### Removing Missing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHiILsjuyd9P"
      },
      "source": [
        "**Function Description:**\n",
        "This code checks for missing or empty values in the dataset. It helps identify which columns have gaps that may need cleaning before analysis.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The command df.isna().sum() uses pandas to find missing values in each column. The isna() function marks missing entries as True, and sum() counts how many missing values each column has.\n",
        "\n",
        "**Inputs:**\n",
        "The input is the DataFrame df that contains the dataset.\n",
        "\n",
        "**Outputs:**\n",
        "The output shows the number of missing values per column.\n",
        "\n",
        "**Code Flow:**\n",
        "When this code runs, pandas checks all columns for missing values and sums up how many there are in each one. The result is displayed as a simple table.\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step helps you see if the dataset has incomplete records. Since the statement column has 9 missing values, they should be removed or filled in before continuing with text preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "4DdkWZKfBFYp",
        "outputId": "eb34d892-4824-4ff0-f900-c7aedcfc95b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "statement    9\n",
              "status       0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>statement</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>status</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp7j2bhiyomF"
      },
      "source": [
        "**Function Description:**\n",
        "This code removes all rows that have missing values from the dataset and then checks again to confirm that no missing data remains.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The command df.dropna(inplace=True) deletes any rows that contain missing or empty values. The parameter inplace=True makes the change directly in the DataFrame without creating a new copy. The command df.isna().sum() then checks again how many missing values are left in each column.\n",
        "\n",
        "**Inputs:**\n",
        "The input is the DataFrame df that still has some missing values.\n",
        "\n",
        "**Outputs:**\n",
        "The output shows zero missing values in all columns, confirming that the dataset is now complete and clean.\n",
        "\n",
        "**Code Flow:**\n",
        "When this code runs, pandas goes through every row in the DataFrame and removes any row with missing values. After that, it counts the missing values again to confirm that all have been removed.\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step cleans the dataset by making sure all records are complete. Removing missing values helps avoid errors or issues in later steps like text preprocessing or model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "qEx9ML2nBFXa",
        "outputId": "468a802e-cdd4-4e66-aa17-dcf7abea81fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "statement    0\n",
              "status       0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>statement</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>status</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df.dropna(inplace = True)\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhcLl3MEBK50"
      },
      "source": [
        "### Looking at target variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0tzKA6Vy6hD"
      },
      "source": [
        "**Function Description:**\n",
        "This code counts how many records belong to each mental health category after removing missing values. It helps confirm that the dataset size slightly changed due to the cleaning step.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The command df.status.value_counts() counts the number of times each label appears in the status column and shows the results in descending order.\n",
        "\n",
        "**Inputs:**\n",
        "The input is the cleaned DataFrame df, which contains only the Normal and Suicidal records.\n",
        "\n",
        "**Outputs:**\n",
        "The output shows how many samples are in each class:\n",
        "\n",
        "*   Normal: 16,343\n",
        "*   Suicidal: 10,652\n",
        "\n",
        "**Code Flow:**\n",
        "When this code runs, pandas looks at all the values in the status column, counts how often each one appears, and prints the results.\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step confirms that removing missing values did not affect the dataset significantly. The updated counts show that the data is still balanced enough for analysis and model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "DOyCQ8FeBKkV",
        "outputId": "86eb5179-d6d1-46f6-ac84-6673ac7e56c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "status\n",
              "Normal      16343\n",
              "Suicidal    10652\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>status</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Normal</th>\n",
              "      <td>16343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Suicidal</th>\n",
              "      <td>10652</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df.status.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zMmrqeDzQ8p"
      },
      "source": [
        "**Function Description:**\n",
        "This code creates a pie chart showing the percentage of Normal and Suicidal records after balancing the dataset. It provides a clear visual representation that both categories now have equal proportions.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The command df_balanced['status'].value_counts() counts how many records belong to each class. The plt.pie() function from Matplotlib creates the pie chart, where labels shows category names, autopct='%1.1f%%' displays percentages, and colors sets custom colors for each category. The startangle=140 rotates the chart for better appearance, and plt.axis('equal') ensures the pie looks perfectly round.\n",
        "\n",
        "**Inputs:**\n",
        "The input is the balanced DataFrame df_balanced, which contains equal numbers of Normal and Suicidal records.\n",
        "\n",
        "**Outputs:**\n",
        "The output is a pie chart titled “Distribution of Mental Health Conditions (After Balancing)” showing 50% Normal and 50% Suicidal samples.\n",
        "\n",
        "**Code Flow:**\n",
        "The code first counts the two categories in the balanced dataset, assigns colors, and plots a pie chart. It then adds labels, percentages, and a title before displaying the chart neatly.\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step confirms visually that the dataset is perfectly balanced. Having equal portions of Normal and Suicidal records ensures that the model will learn both classes fairly during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "YxZJMyeoBUHT",
        "outputId": "f759e79c-f83c-41bd-a4a7-101de148cbab"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Count the occurrences of each category after balancing\n",
        "status_counts_balanced = df_balanced['status'].value_counts()\n",
        "\n",
        "# Define colors for the two categories\n",
        "colors = ['#419D78', '#E0A458']\n",
        "\n",
        "# Create the pie chart\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.pie(status_counts_balanced,\n",
        "        labels=status_counts_balanced.index,\n",
        "        autopct='%1.1f%%',\n",
        "        startangle=140,\n",
        "        colors=colors,\n",
        "        shadow=True)\n",
        "\n",
        "plt.title('Distribution of Mental Health Conditions (After Balancing)')\n",
        "plt.axis('equal')\n",
        "\n",
        "# Display the chart\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMBSluDiBW93"
      },
      "source": [
        "### Looking at raw texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSjZS3phzif6"
      },
      "source": [
        "**Function Description:**\n",
        "This code randomly picks one statement from each mental health category and displays them. It helps give a quick look at the kind of text found in each class.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The command df.groupby('status')['statement'].apply(lambda x: x.sample(n=1).iloc[0]) groups the data by the status column and then selects one random statement from each group. The loop for status, statement in random_statements.items(): prints each status followed by its chosen example statement.\n",
        "\n",
        "**Inputs:**\n",
        "The input is the DataFrame df, which contains the columns status and statement.\n",
        "\n",
        "**Outputs:**\n",
        "The output shows one random statement from the Normal group and one from the Suicidal group.\n",
        "\n",
        "Example:\n",
        "\n",
        "*   Normal: “spring is finally here cherry blossom galore such a shame they are so temporary”\n",
        "*   Suicidal: “Should I just do it? My mom just told me she would not tell me not to kill myself because life does not get better and she wishes she did it herself”\n",
        "\n",
        "**Code Flow:**\n",
        "The code first groups the dataset by the status column. From each group, it selects one random statement and stores the result. Then it prints both the status and the sample statement for easy viewing.\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step gives a quick and meaningful look at the text examples in each category. It helps understand the general tone of Normal and Suicidal statements before doing deeper text analysis or model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3I4uffKBWkW",
        "outputId": "005cc624-6196-4f3f-a907-c4068cc2d185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status: Normal\n",
            "Statement: nmcgivney yeah ploughed around there last night but nothing happening\n",
            "\n",
            "Status: Suicidal\n",
            "Statement: @wolfiecomedy These boys might find it shocking that some internet stranger like myself would say \"fuck these guys\"â¦ https://t.co/VNWeNO1cmv\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Group by status and get a random statement from each group\n",
        "random_statements = df.groupby('status')['statement'].apply(lambda x: x.sample(n=1).iloc[0])\n",
        "\n",
        "# Print the results\n",
        "for status, statement in random_statements.items():\n",
        "    print(f\"Status: {status}\")\n",
        "    print(f\"Statement: {statement}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krUA8U91BdiH"
      },
      "source": [
        "### Adding new features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahC9C5sHz4EM"
      },
      "source": [
        "**Function Description:**\n",
        "This code measures how long each statement is by counting the number of characters and sentences. It then shows summary statistics for both to understand the general structure of the text data.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The command df['statement'].str.len() counts the total number of characters in each statement and stores it in a new column named num_of_characters. The line df['statement'].apply(lambda x: len(nltk.sent_tokenize(x))) uses the NLTK tokenizer to split each statement into sentences and count how many there are, saving the result in num_of_sentences. The describe() function then gives summary statistics such as count, mean, minimum, and maximum values.\n",
        "\n",
        "**Inputs:**\n",
        "The input is the DataFrame df with the text column statement.\n",
        "\n",
        "**Outputs:**\n",
        "The output is a summary table showing descriptive statistics for the number of characters and sentences in each statement.\n",
        "\n",
        "**Code Flow:**\n",
        "When this code runs, it first calculates the character and sentence counts for every record. It then uses describe() to summarize these counts and prints the results.\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step helps understand how long and detailed the statements are on average. It can also guide preprocessing decisions, such as setting text length limits or handling unusually short or long entries before model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3qHCnKABWi9",
        "outputId": "ac6c1197-ada6-4106-fc4f-d4dc6fcf57c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       num_of_characters  num_of_sentences\n",
            "count       26995.000000      26995.000000\n",
            "mean          344.646675          4.393777\n",
            "std           699.146998         10.621908\n",
            "min             2.000000          1.000000\n",
            "25%            40.000000          1.000000\n",
            "50%            99.000000          1.000000\n",
            "75%           384.000000          5.000000\n",
            "max         32759.000000       1260.000000\n"
          ]
        }
      ],
      "source": [
        "# Calculate the number of characters and sentences\n",
        "df['num_of_characters'] = df['statement'].str.len()\n",
        "df['num_of_sentences'] = df['statement'].apply(lambda x: len(nltk.sent_tokenize(x)))\n",
        "\n",
        "# Generate descriptive statistics\n",
        "description = df[['num_of_characters', 'num_of_sentences']].describe()\n",
        "\n",
        "# Display the descriptive statistics\n",
        "print(description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbp9zGpA0BzP"
      },
      "source": [
        "**Function Description:**\n",
        "This code checks if there are any statements in the dataset that are unusually long. It looks for records where the number of characters in a statement is more than 10,000.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The expression df['num_of_characters'] > 10000 creates a condition that filters the DataFrame to include only rows where the num_of_characters column has values greater than 10,000. The result df[...] shows only those rows that meet this condition.\n",
        "\n",
        "**Inputs:**\n",
        "The input is the DataFrame df, which includes the num_of_characters column created earlier.\n",
        "\n",
        "**Outputs:**\n",
        "The output is a filtered DataFrame that displays any statements longer than 10,000 characters. If none are found, it returns an empty DataFrame.\n",
        "\n",
        "**Code Flow:**\n",
        "When this code runs, pandas goes through each record in the num_of_characters column, checks if the value is greater than 10,000, and displays the rows that meet this condition.\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step helps identify extremely long statements that could affect text analysis or model training. If such outliers exist, they might need to be removed or shortened to keep the dataset consistent and manageable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "dkOpdsiKBjp1",
        "outputId": "43346998-a390-4832-9596-f1c6bf0dbd36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               statement    status  \\\n",
              "7483   AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA...  Suicidal   \n",
              "8185   I have only 1 person I can somewhat open to bu...  Suicidal   \n",
              "9439   I cannot TAKE IT ANYMORE. I cannot TAKE IT ANY...  Suicidal   \n",
              "11815  I am someone living in Turkey. My age is proba...  Suicidal   \n",
              "13708  I do not expect anyone to read this rambly mes...  Suicidal   \n",
              "13877  I have been thinking about posting online for ...  Suicidal   \n",
              "14488  This is a a vent. I (29M) really do not know w...  Suicidal   \n",
              "\n",
              "       num_of_characters  num_of_sentences  \n",
              "7483               25302                 1  \n",
              "8185               27390               237  \n",
              "9439               32759              1260  \n",
              "11815              10219               180  \n",
              "13708              12227               118  \n",
              "13877              12028               132  \n",
              "14488              11075               133  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fdbc0935-28c7-4818-bf25-1f6a9ba6ead5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>statement</th>\n",
              "      <th>status</th>\n",
              "      <th>num_of_characters</th>\n",
              "      <th>num_of_sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7483</th>\n",
              "      <td>AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA...</td>\n",
              "      <td>Suicidal</td>\n",
              "      <td>25302</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8185</th>\n",
              "      <td>I have only 1 person I can somewhat open to bu...</td>\n",
              "      <td>Suicidal</td>\n",
              "      <td>27390</td>\n",
              "      <td>237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9439</th>\n",
              "      <td>I cannot TAKE IT ANYMORE. I cannot TAKE IT ANY...</td>\n",
              "      <td>Suicidal</td>\n",
              "      <td>32759</td>\n",
              "      <td>1260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11815</th>\n",
              "      <td>I am someone living in Turkey. My age is proba...</td>\n",
              "      <td>Suicidal</td>\n",
              "      <td>10219</td>\n",
              "      <td>180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13708</th>\n",
              "      <td>I do not expect anyone to read this rambly mes...</td>\n",
              "      <td>Suicidal</td>\n",
              "      <td>12227</td>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13877</th>\n",
              "      <td>I have been thinking about posting online for ...</td>\n",
              "      <td>Suicidal</td>\n",
              "      <td>12028</td>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14488</th>\n",
              "      <td>This is a a vent. I (29M) really do not know w...</td>\n",
              "      <td>Suicidal</td>\n",
              "      <td>11075</td>\n",
              "      <td>133</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdbc0935-28c7-4818-bf25-1f6a9ba6ead5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fdbc0935-28c7-4818-bf25-1f6a9ba6ead5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fdbc0935-28c7-4818-bf25-1f6a9ba6ead5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a20ffc3d-4138-4521-87f4-14588008ebf8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a20ffc3d-4138-4521-87f4-14588008ebf8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a20ffc3d-4138-4521-87f4-14588008ebf8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[df['num_of_characters'] > 10000]\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"statement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           PLEASE I JUST WANT IT TO STOP\",\n          \"I have only 1 person I can somewhat open to but I have only done so to a certain extent and try to refrain from doing it at all for the most part. I feel guilty as if I am bothering them with unfairly dumping my bullshit onto them and as if I am doing it for attention or pity. I honestly have no clue how long this will end up being. Whether this story grosses you out, makes you hate me, or even if you choose not to read it, everything is fine with me. It does not really have a point. I just felt like Id never actually let my thoughts out properly and so this is my trashbin.Was raised in a single mother household and never knew my father. Mother divorced him for being psychotic and threatening not only her life but the lives of his children as well. This was after years of her holding out believing it was her duty to sacrifice herself to let her children have a financially stable home with 2 parents. We ended up in a very low class town with minimal income but my mother worked herself to the bone with low paying jobs in an attempt to make sure we still had as good of a life as she could make. Unfortunately I still ended up being a weird kid. Not really sure why but I have always wondered if I had a disorder that was simply never noticed and properly diagnosed. I know now though that I have severe anxiety problems which were hereditary. She spent every last ounce of her strength just trying to provide for the family so she had very little left over to actually raise the children. Once I got into the public elementary school my weirdness ended up with me never developing any connections. Eventually there was severe bullying. I would never paid any attention to it till my most recent years when I started to reflect on why I am the way I am now, but I know that some of it definitely mentally changed me in very not good ways. Though all these years I never thought of it as such. For what I believe was the reason above I ended up dropping out of the school system after at least a year of problems. The biggest was me refusing to go to school by faking epileptic seizures as a way to get out. I actually had epilepsy but all of the \\\"seizures\\\" I ever had at school were fake. The final nail in the coffin was 1 particularly violent bully beating the shit out of me and stomping my head into the concrete pavement for almost a minute like he was playing dance dance revolution at an arcade. Teacher was too scared to physically stop him I guess? Stayed out of the system for like 3-4 years while the public school shut down. We live in an extremely economically dead town. Like the majority of the towns roughly 1000 population are under the 10k annually mark (including us) and barely survive solely off government benefits and the low cost of living. That was when I first started to seclude myself off. It was not terrible but at the same time I had no real social connections. I did things like go on occasional outings with family members and such but I had no friends or social groups at all. Eventually I started to really dive into my playstation 2 and slowly started sticking there more and more as time went on. My grandparents both finally fell down ill due to old age. My grandmother developed parkinsons and my grandfather went through several bad falls as well as slowly developing dementia. This was an unbearably huge amount of stress on my mother who was already being torn apart by how hard she was struggling to keep the household up. Eventually she decided to sacrifice her job in exchange for taking up the home healthcare position of taking care of my grandparents. With this she would work literally next door to us, be able to take care of her parents when no one else in the family would, and she would still make an income. It was shaky but things were still fine back then. Around the age of 11 or so (bad memory of things back then) she decided to pay a heavy amount of money to put me back into school. There was a VERY small little private school in town that was run by an older gentleman named Mr. G, 3 teachers, and maybe a total student body of 25 or so children in various grades split between those 3. 2 of them were very nice older women named Miss D and then my teacher named Miss N,. I guess I had problems with anxiety but eventually I managed to be somewhat happy. Unfortunately the third teacher, Miss P who was the daughter of Miss D, was a very difficult person. She had extreme anger issues, seemed to just dislike children as a whole, and had absolutely no patience for anyone who lacked. Miss N was a much more Elderly woman than the other 2 and at some point she became far too ill to continue her teaching job. The remaining kids were mostly moved to Miss P's class with the only exceptions being the much younger children in the lower grades. Every single day was a living hell for me. The simplest way to describe it is that she held extreme animosity towards the weaker kids. If you were falling behind in the pace of your work, or if you were not producing grades that she was happy with, or if you did not understand something, she just hated you. When you did something like this she would threaten you, scream at you, talk to you like she was about to physically beat the shit out of you, oftentimes not so subtly threatening to actually do so. She used intimidation like standing directly above you in your seat and silently glaring you down. it would be even worse when she would bend down and put herself right in your face and start with her threatening. Or she would take a heavy book and slam it in front of you. There were at least 2 kids that definitely had learning problems, like a young little blonde boy named Tyler. The poor kid would often be the last to finish his work, or maybe it was even a group of 3 of us. she would slam her hand down on her desk in the corner, look at us like she was about to kill us, and then tell us in the most threatening manner that she could muster \\\"Get it down NOW\\\". The school had a physical discipline policy that was based on parental permission. she would often take Tyler somewhere to beat his ass with a belt when he was not performing like she wanted. The other method she used a lot was what I liken to a military \\\"shark attack\\\". she would take the student to a separate part of the school, plop them down in a chair, and start shouting in their face. She berated them on why they cannot do what she wants them to do, why they cannot do it fast enough, why cannot you understand this or that when you should be able to understand it, and when some poor kid can only respond with \\\"I do not know\\\" she just lays on harder. She always told us that we CAN do it how she wants but we are just lazy or do not want to do it. Or that our parents did not raise us properly.The principal, Mr G, apparently knew about some of this but Miss D did her best to protect her daughter. Some of the parents would become aware of this and many different students over the years would get taken out because they could not handle Miss P. Miss D was honestly a nice and good hearted person but I guess she simply loved her daughter and did not want to see her fired. I still do not know to this day how the school had not been hit with any legal problems but maybe what she was doing was not considered abuse or anything.Eventually history repeated itself and I continued to miss more and more school. I would wake up hours before it was time to leave for school because I was terrified of going and could not sleep. A lot of times I would cry on the way there and beg my mother to not force me to go. I think I had a hard time explaining to her why I hated school so much. She knew the teacher was causing issues but was not sure of what to do. Because she was soft she would let me skip school pretty often on days like that, but she was also pressed as she was paying the school a huge fee monthly for me to go, I was losing a lot of school work due to missing everything, and she was also legally pressed as there was a child law stating that you could not miss so many days of school. Finally after so long of it she mentally could not handle juggling my problematic school life and her other responsibilities so she pulled me out. I was labeled as being homeschooled so we were legally safe but I never touched a single bit of homeschooling work at all. Same situation as before. I had not managed to build any relationships with people and had no connections to social groups. I went back to my little room and continued to play video games. As the years went by I became more and more secluded and slowly degenerated as a person. Stopped interacting with even my family members, stopped leaving the house for days at a time, stopped interacting with my mother, stopped interacting with the house, ect. Then came things like neglecting my basic hygiene, neglecting my responsibility to assist with the household, ect. I am not worried about revealing this as I can remain anonymous but I believe my hygiene and standard of living was probably far below what most people could imagine. At the worst points of it I could have gone a month or over without bathing and years without brushing my teeth. My room had become a literal vile trash heap filled with soda cans, junk, dishes, and rotting food. How I never contracted some horrific disease is beyond me, and somehow I came out with a perfectly healthy set of teeth despite horrible yellowing. Through it all my mother destroyed herself trying to deal with me as a life sucking parasite living in the back of her house and her slowly dying parents that were succumbing to old age and terrible illnesses. I sat by staring at my computer screen, having basically no human interaction with anyone and even amongst online groups still being a weirdo that never got along with people, not paying attention to both her and the house falling apart. Even in my little computer world I was not satisfied though. I still do not understand a lot about myself but I believe I sought out video games as a form of fulfillment as I have nothing else. I looked towards competitive games or extremely grind heavy games as a way of feeling like I could accomplish something and feel like I had worth. Unfortunately I quickly learned that I was pretty mediocre at these things as well. Even if I could happily play a game 10, 12, 14 hours a day I still could not succeed how others could. I started to learn very quickly that regardless of what I dived into I was also lacking. I believe this led to my complex of believing that I am incapable of doing anything at all. Somewhere at around the age of 18 I got some awareness and finally realized where I would gone. Spent all of those years thinking \\\"No way I could end up like this. that is impossible.\\\" and then suddenly I open my eyes and I am already there. Seen my husk of a mother dealing with a dysfunctional family, both from her children and her siblings. Seeing everything I would loved as a child decayed and gone. I had a cousin named Jeff and his father named Sammy who I loved more than anyone else when I was a kid. When I was much younger Jeff died after a life fighting against cancer which left his father and mother broken. Instead of trying to connect with my uncle which could have done us both good I instead spent my time shutting myself off from my family, and eventually he also passed away from a broken heart and crippling illness. I cannot tell you how much I regret that. In 2017 my grandfather finally passed away from his problems, and then about 1 year later my grandmother followed after him. That was the end of my mothers employment and thus any income we had. Her mental state was destroyed by the years of stress and then the loss of her parents, and she was already in her 50's on top of being physically worn out so even if she wanted to try she was no longer fit for work. I was a pile of shit with mental issues who could not even interact with people properly anymore much less join the workforce. What little education I started out with had been completely forgotten and I forget how to even write. I can still write letters but there is almost no way I could handle anything past a few simple words. I only relearned how to write my name in cursive because I had to start filling out my own paperwork in hospitals and such. I never actually remembered or possibly even learned how to use proper grammar and punctuation. What I am doing now is only from me copying what I see other people do and trying to figure out how it is used from there. I have tried self learning things in the past but I get overwhelmed and it feels like I cannot grasp anything no matter what I try. We spent the next several years in financial hell. Begging friends and family for money where we can just to keep utilities and internet on, of course using government programs for things like food stamps. There were plenty of times where we would lose electricity or water anyway as there is a limit to begging and what others can do to help you when they are struggling with their own lives. Our relatives in Texas were a bit more successful and it was in large part thanks to them that we even managed at some points. Even still we have had situations where we lived without water for months before, electricity for weeks, ect. We also managed to rack up a utility debt to the town which is where we would lose the water a lot. It was due to an error on their part where they failed to shut off our gas line and thus charged us for utilities we did not use. We were constantly hit by struggle after struggle but life continued on. Somewhere along the way I developed a back disability. It could have been hereditary, it could have been a random occurrence, or it could have been a result of my terrible lifestyle. I do not know the answer. At first it was not anything major but it slowly progressed to be worse and worse as time went on. After so long we started to piece things back together through a few different methods. Specifically we relied on a deposit that originally belonged to my grandparents but my family handed it over to us since we needed money the most. Then my grandfather's precious car that had decayed away in his garage was also sold. This money at least helped us for a few months until we finally managed to get more government assistance and deal with the town. We managed to get a program that pays for our electricity and then got the town to ignore the debt of our water bill for the time being while we pay a small amount every month to keep it on. Eventually though I started to crack. Over the years I refused to swallow the notion of depression. I had lived my entire life by having my mother take care of me, sacrificing herself to deal with me even though she should not have. I had not changed my ways much but I started to develop a mentality that I did not deserve anything from anyone, especially not the right to be depressed. I would have moments where it would creep up on me, but I would throw it away and ignore it. However time went on and the guilt only piled up. I could not change my ways or do anything to change my life. I am nothing but a burden and I cannot change it. The fact that I would always revert back to my ways and the fact that years went by without any sort of change killed me so much. Then one day about a year ago I watched a motivational video from an old man who started from a truly low position in life. He was a bright and strong old guy who tried to convince the younger generation that they can do it and that he understands that life is hard for people in these times, maybe even harder than it was in his. I watched a few of his videos and the only thing I could think was \\\"I am nothing like this person. I cannot be as strong as this person. I cannot change my life like this person. I am sorry for failing.\\\". that is when I first started hurting myself. was not anything major. Was an old pocket knife and I did not aim deep. And you know? It felt good. Not in a physical way of course. I would been taking so many painkiller/muscle relaxer pills that I did not feel much. However I would always thought that I could not even commit suicide if I wanted to because I would be too weak to even endure the pain or have the guts enough to because it. But those few cuts proved me wrong. I could do it and it was pretty easy, and that made me happy. For about a week I would continue making cuts here and there just to continue reaffirming that feeling of accomplishment. I just passed the cuts off as my huge cat losing his marbles and attacking my arm. Since I would never really interacted with my mother much and never allowed myself to show any sort of symptoms of depression she did not even begin to suspect anything else. But then an argument happened. It was something stupidly simple. I had a pack of meat that I wanted to take out of the freezer to defrost, but it was 2 separate packs joined in the middle by tough plastic. I could not separate it and lazily threw the entire thing into the fridge to defrost. My mother stopped me and proceeded to lecture me about how I always waste so much food and I got annoyed. I just grabbed the meat and was going to chuck it back into the freezer for another time but then she got pissed at that as well and jerked it out from in front of me and started telling me how I am always so childish, impatient, lazy, and \\\"I am beginning to think that you will never change\\\". This one little line broke something. I thought to myself \\\"She also understands that I am worthless and that I will never change or become better\\\". It was like I knew that she knew the entire time but hearing it and thus confirming it is an entirely different thing for me. Even though I of course knew that is not what she meant I could not help but think about these things. I quietly slinked off into my room like I normally do but once I was behind a closed door and was not being bothered I silently broke down. I cried, I laughed at myself, and then I started cutting more. This time was harder. I was angry at myself with how fucking pathetic and disgusting and how much of a soul sucking worm I was. After a few larger cuts than normal I really broke down and finally started going for real deep wounds.Then I looked out of the corner of my eye and noticed an old fish fillet knife on my desk. I enjoy knives as a hobby so I had a lot of different stuff scattered around my room. I took it, thought about what sort of damage I could deal with it, and I was happy at the thought. To avoid explicit details I ended up with 4 deep gashes. I was not sure if I was necessarily thinking of committing suicide with that or not. I almost wanted it but I also avoided cutting directly on the wrist and also remained aware the entire time that I knew a better method to ensure it would work if I committed to it. I did not feel much of anything, maybe not even the slightest burn. could have been adrenaline, could have been the pain meds, could have been both. However as I sat there for a while breaking down further and further while I continued to bleed badly the thought crossed my mind that I could have actually done potentially fatal damage. I never really had a plan to begin with for hiding such massive cuts but they were far beyond the point of just wrapping them up and pretending it was nothing. that is when my legs gave out, my vision blurred, I became ultra light headed, and my arms and hands became extremely numb while tingling super hard. Id suddenly got scared and thought that I might have killed myself somehow. I stumbled to the front of the house and showed my mother what happened. Told her I loved her and was sorry for failing her and then just sat down on the kitchen floor and just kind of blurred out from there. A nearby off duty EMT rushed over and took a look. Nothing fatal as the knife had been dulled over the years without me knowing but stitches were definitely needed so she patched me up as best as she could and I was rushed to a hospital in a far off city. Closest city could not accept me due to covid or something so I ended up going to a larger but further away city. Mother cried so much on the way there and she was absolutely traumatized. Ended up saying goodbye to her at the hospital entrance and then sat in a holding cell for what was probably about 3-4 hours. Went through the process of getting patched up and once day break hit I got shipped off to a mental facility nearby. I spent about a week there. I had more human interaction in that 1 week than I had in the entire 10 years leading up to that point, and most of it was me silently sitting in the corner. Despite that though the facility was not worth anything at all and I am still not sure how people are cured there. Maybe it was a holding facility and not an actual hospital but I do not know and never cared to know. It was just a depressing common room where everyone just sat around in uncomfortable chairs, drank decaffeinated coffee, and tried their best to sleep through the day until they were allowed to go back to their rooms for the night. Met some interesting characters. The people in there ranged from people with major disorders, to people in drug remission, people coming off an alcohol trip, and even something like anger problems. Got to meet a gorgeous young hood girl named Audrey who I instantly developed a crush on and also got to experience what it was like having a roommate even if I absolutely hated it. Was picked up by my mother and uncle after my week was up and really had not received any sort of help or counseling. Id felt like an entirely different person though just finally being around people and even briefly opening up about myself to a few people around me. Had some sort of psychiatrist call center try to help me afterwards but all it amounted to was a group of random people who I formed no connection to calling me up whenever they felt like it to ask me if I was ok and if I needed any more meds. I was probably at fault since Id already had a hard time opening up but I felt even less inclined when it was someone I did not care about or know over the phone. Suddenly for a short bit I had family members swarming around and feeling like they had to somehow help me. Was given my first cellphone as I had not ever needed nor wanted one previously, and not but maybe a few weeks later my cousin contacted me to tell me he wanted me to work a part time job. Its really low hours which works in my favor with my disability and its a simple cleaning job so I can pick it up so easily. I thought of this as a first step that would hopefully give me a mentality that I can do better and I can be of use to people. The money is next to nothing but for the first time in years we do not have to ask someone for assistance the moment we need even the smallest of things. Can keep basic household items around, keep my pets fed, try to keep bills paid, ect. After about 2 or so months I turned towards fixing my back. If my legs recover from the severe muscle pains I experience when walking then I could hold a full time job with good pay and from there its just a slow process of building myself up. The ineptitude I feel, the lack of education that haunts me, the disability that holds me back, all of it could be fixed with some time. I felt so happy and it was such a new feeling that I had not felt in so long. that is when everything quickly came caving in. So far my doctors and related medical procedures were all moving at a crawl. I spent several years dealing with a doctor that had to be demanded to move through several visits before they would actually do something, and I repeatedly kept getting thrown back and forth between tests and random crap. I ended up in physical therapy several times but that never amounted to much because apparently government health insurance does not afford particularly quality or motivated therapy sessions. That went nowhere fast and so Id spent the years up until that point just hopped up on a high dose of painkiller/muscle relaxers. However all of a sudden everything sped up real damn quick. There was immediate discussion about consulting a neurosurgeon which we spent a while trying to find due to not only the limitations on what the state had available but also what we could find with our insurance. Dumb doctor seemed optimistic and told me it should be easily treatable. Finally got to meet my neurosurgeon for the first time and he was even more optimistic. He spun a tale of how so damn easy and quick it would be to fix a busted disc and that even if the back pain was not 100% cured there was no way he could not fix it up so that my legs were not fine again. Said everything was a guaranteed easy operation. So on my very first consultation due to my naivety and stupidly thinking I could trust doctors I agreed to a surgery. Short version of that is several shady things happened with that doctor and after about a month or 2 of recovery I could safely say that not only had the surgery failed but I was not at least 2 or 3 times worse off than I was previously. Now that were later into 2021 I have been told after a follow up visit that the disc is no longer salvageable and the damage may yet get worse as there are signs that more discs will degrade and blow out in the future. A surgery to potentially stop the problem from worsening has been suggested but all of his previous enthusiasm is gone and he believes there is a good chance the rest of my discs will go bad regardless of what happens. For now I am taking more pain meds than before just trying to keep my little job together but who knows when that will start to fail as well. In that time span of my cutting incident to now I rose up higher than Id been in years only to fall lower than Id ever been before mentally. Things like my hygiene have gotten to acceptable levels. I still have anxiety about so many things that eat away at me on a daily basis but I have gotten better at talking to people even if I cannot manage to build social connections. But I have completely lost hope of ever escaping poverty, ever having a body that is not too weak to do what I want, trying to build a normal social life and make up for all those years I wasted, or even escaping from behind my little computer screen. Any time I try to think about it, or when someone tells me what I should be doing, somewhere along in that plan that I am cooking up I reach a roadblock that stems from something of these 3 issues. I have come to hate everything about myself and where I am at now. Even if I try to explain it away I still blame myself for ending up like this. Suicide seems to be the only thing I can think about now as I have lost all form of motivation to even do the things that I once enjoyed. I am simply trying to pass through each day until hopefully I hit another emotional breakdown that will give me the push I want to overcome everything else and just end it. Rather than wasting my time and spending my entire life self loathing and living like this I decided that if nothing changes by the time I am 25 in 2 more years Ill resolve myself to end it if I do not do it sooner. Venting and dumping my story here if that is fine. it is ok if it needs to be removed for whatever reason.\",\n          \"I have been thinking about posting online for a few days now, thinking maybe there is a solution or an angle that I am missing. **This is LONG**. I am starting from the beginning, because I feel like there may be a trend. Also, it almost feels nice laying everything out in the open. I apologize for any problems you may have with the formatting, past and present tense writing, or keeping shitty track of my own timeline. I wrote this on my phone in bed, and ended up emailing it to myself to post it on a burner profile.As the title says, I do not want to die. I just want to feel happy.Ever since I could remember, suicide or death has always been on the radar. I remember getting upset over something as a kid, and saying I wish I were dead. I have always had a temper, and I would often go from 0-60 emotionally extremely fast. I never made any suicide attempts pre-puberty, but the idea would be in my head more frequently as I got older. I was on various medications as far back as I could remember until I was about 16. I was diagnosed with ADHD when I was young, and I was suspected to have BPD later on, but I was never fully diagnosed with it. I ended up stopping my meds on my own when I was 16. Once I hit my pre-teen/teenage years, the problems seemed to pick up pace. At some point, seemingly coinciding with the uptick with all my issues, the idea of death and suicide changed from just an idea, to a viable solution to my problems in life. It went from \\\"I wish I were dead\\\", to \\\"I could take my own life and things would not be an issue\\\". My first \\\"attempt\\\" happened in my early teens. Something I cannot remember happened, and I ended up smashing my bedroom window and holding the glass to my neck. My mom and step dad talked me down at the time, and they took me to the hospital where I was assessed and released shortly after them determining I was not a danger to myself anymore. Years 16-20 were probably the best of my life. At some point when I was 15, I had something like an epiphany where I realized I was in control. Everything made sense. If there was a problem or internal conflict with myself, I could sit down and come up with a solution. I understood that I could not rely on my mom for every answer to every problem I had. I went from barely finishing 3 courses a year in grade 10 and attempting to quit, to completely catching up in grades 11 &amp; 12, a 4.0 GPA, acing exams, and making honor roll. I was very introverted in school, but focused on the goals I had set for myself. I never socialized outside of my classroom, but I had regular friends that went to a different school, that I visited on weekends and breaks. After graduating, I got into the work force doing a few different jobs trying to pick a career path. A little over a year went by and I finally got into what I felt was a serious relationship. We were childhood friends, and I was 110% serious on staying with her for the rest of my life. She had a 3 month old girl when we started dating, and I did my best to step into the father role at 20. I was stressed out, money was tight, we lived about an hour away from each other, and she put me through some unnecessary drama. I felt a bit trapped in my job, because it paid good for a 20 year old with no education, and I had to start saving money to build a future with her and the baby. I worked hard, and took any opportunity I could to gain experience and move up. Long story short though, we broke up after about 4 months, with me going through the expected emotional turmoil. I remember being upset one night, and deciding to go for a bike ride at night between my town and the next. It was raining, I was wearing all black, and it was a very busy road. I did not care. I wanted someone to hit me without it being my fault. I made it to the next town without incident however, and I took the bus back home. Despite starting off the ride wishing I would be hit, it ended with feeling proud of myself, not expecting to be able to ride that far. After that night, I started riding my bike frequently. I would push myself further at every opportunity, it was like a mixture of meditation and blowing off steam. At nights to relax and get out to blow off more steam, I would end up walking into my town every night, buying a tea, and walking back home. For whatever reason, walking made me want to start running. I eventually took up running in addition to biking, and I even considered taking part in triathlon the following year. I was one of my walks one day, still a bit hung up on my failed relationship, and I was hit by another epiphany. I had no commitments, no debt, I was in the best shape I had ever been in, I was suddenly incredibly high on life. That was the moment I decided that I was going to chase my dream trip, and that I was going to go work up north to save money for it. That summer was the best time of my life. I partied a few times every weekend, I made life long friends, I lived every moment to the fullest. Eventually the fall came, partying season was over, and it was time to get to work. I quit my dead end job, gave my car away, packed a suitcase, and flew up north to stay with my biological dad and my step family. My plan was to work away from home for a year, and move back after my trip. They let me stay in their basement living room on the couch, helped me get some oilfield certificates, and pointed me in the direction to find a good paying job. Eventually I got a job at a heavy duty mechanics shop. I worked there for about 3 months trying to get into an apprenticeship. I was a little stressed out from living out of a suitcase and sleeping on a couch every night, I was working about 11 hour days 6 days a week, but it was all for my trip so every paycheck seemed like a step forward. I continued to exercise to blow off steam. Eventually, the stress compounded too much and I was in need of some change. There were not enough journeymen to sponsor me for an apprenticeship, and things seemed to hit a dead end. I received an opportunity to work on the railway around this time, which involved relocating. Hotel rooms and meal allowance was provided so I jumped on it. For the rest of the season into winter I worked hard. The physical labor was intense and sometimes dangerous, working up to 18 hours a day every now and then. I was making money hand over fist and saving money like mad. It was not long before I had enough for my trip, but I kept working the rest of the season to make extra, only going home to see family and friends about every 2-3 months. My grandmother passed away while I was up there working, and I came home to be with family. I ended up asking for the winter off to take my trip because it seemed like a good time to do it. I went on my trip to this country for the second time, but all alone. I was diving head first into a completely different language and culture with no one there to catch me if I fell. I explored, I got lost, I had to work my own way through challenges, I learned a lot. After about 4 weeks I decided to return home, going through most of my budget and kind of feeling homesick. For the next few months, I roomed with some buddies and chilled out until the work season started again. I started a relationship with a girl before the trip, and picked up where we left off when I came home. Springtime, the railway maintenance season starts. I start taking on more responsibilities at work, and only staying out for 1-2 months at a time. This is where life started to degrade. I worked the usual long hours, took on more stress, but I was making money and learning lots. The stress was constant though. You were usually under pressure from a train coming at some point, and everything had to be done properly so it could pass over your work safely. Causing a derailment would be disastrous, and potentially deadly. Over the years I continued to take on more responsibilities, learning new roles and working long hours. I think the second season was when I started to disassociate a bit to power through the long hours and miserable work. I started to drink regularly as an outlet instead of exercising, thinking I had enough of a work out during the day to justify some beers. As well, life on the road/hotel rooms meant that you were usually eating out or eating shitty meals. I gained about 100lbs in four years. Maybe eating out was a way to cope as well. This lifestyle continues today. I lost the weight a few times, but it always came back fast because of the overall lifestyle and stress. Fast forward to 27 years old. Still doing long hours, pretty jaded from the work and lifestyle, and still heavy. My girlfriend has stuck around through all of this somehow. I was coming home every few weeks though, so that was pretty cool. For probably a few reasons, I developed some severe anxiety issues. It got to the point where I was pacing in my hotel room, with intrusive thoughts telling me I should kill myself. I would be in tears, the only way out was to die. I usually ended up smoking weed pretty heavily to numb myself and go to bed. I decide to get some help from my doctor, who referred me to a psychiatrist. My schedule meant that appointments would be very spread out and change would be painfully slow. After about a year, we finally managed to get me leveled out and my anxiety down about 50% with the help of some medication. I switched companies in the same industry for some more money and better opportunities. Still long hours on the road though, same stress, and living out of hotel rooms. Eventually, I came to the conclusion that I was dissociated to the point where the days would pass by and I would not remember much. I do not even blink at a 20 hour day anymore. I do not feel anything. I do not the have passion that I once had, no happiness, no enjoyment, excitement, or entertainment. I lost my hobbies pretty much when started my first year, and I always focused my spare time on visiting people or running errands while at home. Things got bad enough to the point where if I had more than a week off work, I would have angry outbursts/withdrawal from work. Even though I going home more, I did not know how to enjoy myself or blow off steam anymore. I think all the hours at work, combined with the schedule, made me dysfunctional.That brings me to this year. New position in management, significantly less money but more experience for the resume. I still hate the industry, and I am still on the road 90% of the year. reached out to my doctor again because the suicidal ideation has returned. It took about 3 months, but I was eventually set up with a psychiatrist again. She did not do much though. She took me off some of my old meds and doubled another. We probably only had about 4 or 5 appointments over the phone before she said she could not help me. Now here I am. I am going through depressive episodes again, thinking the only way is suicide. I am in debt from stupid decisions over the years, I am fat, with no goals or hobbies, no savings, living paycheck to paycheck, priced out of the housing market because I did not buy in my early to mid 20's, and the doctors gave up on me. I turn 30 in a few months, and I have decided that if life has not turned around or I have not had another \\\"epiphany\\\" by then, I am going to bring things to an end. I have not made any attempts because I am not ready. it is going to be a one time thing with 100% certainty, and I do not want to humiliate myself by not succeeding. I have the plan figured out, but I will not share the details here because I do not want to give anyone ideas. I do not want to die, it will devastate my girlfriend, the same one I have had from the beginning of all this crap. It will probably ruin my mother, family, and close friends. I will never see my cats again. The last thing I would ever want to do is hurt anyone. But life has not been going the right direction for almost a decade now, and things only seem to be getting worse. I am tired. I do not want to die\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Suicidal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_of_characters\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9427,\n        \"min\": 10219,\n        \"max\": 32759,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          25302\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_of_sentences\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 431,\n        \"min\": 1,\n        \"max\": 1260,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "df[df['num_of_characters'] > 10000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcXLmR6FB9GY"
      },
      "source": [
        "# **3. Text Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CofeerxjCD5N"
      },
      "source": [
        "### 3.1. Lowercasing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FMKWGYe0dGd"
      },
      "source": [
        "**Function Description:**\n",
        "This code converts all text in the statements to lowercase so that the model treats words like “Happy” and “happy” as the same. It also renames the original column to keep both the original and processed versions of the text.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The line df.rename(columns={'statement': 'original_statement'}, inplace=True) changes the name of the statement column to original_statement. The next line df['statement'] = df['original_statement'].str.lower() creates a new column named statement with all text converted to lowercase using the str.lower() function.\n",
        "\n",
        "**Inputs:**\n",
        "The input is the statement column from the DataFrame df that contains the original text.\n",
        "\n",
        "**Outputs:**\n",
        "The output is an updated DataFrame with two columns for text: original_statement (unchanged) and statement (lowercased).\n",
        "\n",
        "Example:\n",
        "\n",
        "*   Original: “Gr gr dreaming of ex crush to be my game, God”\n",
        "*   Lowercased: “gr gr dreaming of ex crush to be my game, god”\n",
        "\n",
        "**Code Flow:**\n",
        "When this code runs, it first renames the original text column, then creates a lowercase version of each statement, and finally displays the first few rows to confirm the changes.\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step helps prepare the text for further preprocessing. Lowercasing ensures that the model does not treat the same words differently just because of capitalization, making text analysis more consistent and accurate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZllkxwTFCJMB",
        "outputId": "e3378517-2fcc-44d7-defe-130c1511a5be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  original_statement  status  \\\n",
              "0      Gr gr dreaming of ex crush to be my game, God  Normal   \n",
              "1                                 wkwkwk what a joke  Normal   \n",
              "2  Leaves are also standby in front of the PC ......  Normal   \n",
              "3     Thank God even though it's just a ride through  Normal   \n",
              "4  wedding teaser concept using the song day6 - o...  Normal   \n",
              "\n",
              "   num_of_characters  num_of_sentences  \\\n",
              "0                 45                 1   \n",
              "1                 18                 1   \n",
              "2                 87                 1   \n",
              "3                 46                 1   \n",
              "4                 71                 1   \n",
              "\n",
              "                                           statement  \n",
              "0      gr gr dreaming of ex crush to be my game, god  \n",
              "1                                 wkwkwk what a joke  \n",
              "2  leaves are also standby in front of the pc ......  \n",
              "3     thank god even though it's just a ride through  \n",
              "4  wedding teaser concept using the song day6 - o...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89565aff-57cc-4692-8351-2ddc5c1706a0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_statement</th>\n",
              "      <th>status</th>\n",
              "      <th>num_of_characters</th>\n",
              "      <th>num_of_sentences</th>\n",
              "      <th>statement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Gr gr dreaming of ex crush to be my game, God</td>\n",
              "      <td>Normal</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>gr gr dreaming of ex crush to be my game, god</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wkwkwk what a joke</td>\n",
              "      <td>Normal</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>wkwkwk what a joke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Leaves are also standby in front of the PC ......</td>\n",
              "      <td>Normal</td>\n",
              "      <td>87</td>\n",
              "      <td>1</td>\n",
              "      <td>leaves are also standby in front of the pc ......</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Thank God even though it's just a ride through</td>\n",
              "      <td>Normal</td>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>thank god even though it's just a ride through</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wedding teaser concept using the song day6 - o...</td>\n",
              "      <td>Normal</td>\n",
              "      <td>71</td>\n",
              "      <td>1</td>\n",
              "      <td>wedding teaser concept using the song day6 - o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89565aff-57cc-4692-8351-2ddc5c1706a0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-89565aff-57cc-4692-8351-2ddc5c1706a0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-89565aff-57cc-4692-8351-2ddc5c1706a0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b71c6758-a34b-48fe-8d89-3059f627fbf4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b71c6758-a34b-48fe-8d89-3059f627fbf4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b71c6758-a34b-48fe-8d89-3059f627fbf4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 26995,\n  \"fields\": [\n    {\n      \"column\": \"original_statement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26683,\n        \"samples\": [\n          \"I have been here long enough and I am ready to leave now, I am not young so my dearh will not be a tragedy. I have had enough of my pathetic existence. I am thinking of going through with it next week, I wonder how long it takes to actually die from hanging... When do I get to die?\",\n          \"i honestly do not know how much longer i can go. I have attempted many times in the past by overdosing but sadly survived. one of the biggest reasons why I am still here is, bc i do not want my parents to have to bury me. i do not want to pass my pain onto others, but i really do not have much left in me. i have dreams &amp; goals, but they seem so impossible with depression draining me, &amp; suicide on my mind 24/7. I have been to the psych ward many times, tried many different medications, &amp; have seen therapists. my friends &amp; family are supportive, but they really do not understand. i just wish i was already gone. cannot keep going\",\n          \"in the photoshop\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Suicidal\",\n          \"Normal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_of_characters\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 699,\n        \"min\": 2,\n        \"max\": 32759,\n        \"num_unique_values\": 2385,\n        \"samples\": [\n          4043,\n          5845\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_of_sentences\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 1,\n        \"max\": 1260,\n        \"num_unique_values\": 90,\n        \"samples\": [\n          61,\n          30\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"statement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26664,\n        \"samples\": [\n          \"i'll squeeze the cloth so it's almost dry.\",\n          \"lol what anna schmance i soo wan na meet up with you in the holiday man haha im missing you so bad\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df.rename(columns={'statement': 'original_statement'}, inplace=True)\n",
        "\n",
        "df['statement']=df['original_statement'].str.lower()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1-QOYVCCN_O"
      },
      "source": [
        "### 3.2. Removing URLs, handles, punctuation and special characters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0nbX30n1XuA"
      },
      "source": [
        "**Function Description:**\n",
        "This code cleans the text by removing unnecessary elements such as URLs, links, user handles, punctuation, and special characters. It helps make the text simpler and more consistent for analysis.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The function remove_patterns(text) uses re.sub (regular expressions) to find and delete specific text patterns. The code r'http[s]?://\\S+' removes URLs, r'\\[.*?\\]\\(.*?\\)' removes markdown-style links, r'@\\w+' removes handles that start with “@”, and r'[^\\w\\s]' removes punctuation and special characters. The strip() function removes any extra spaces from the start and end of the text.\n",
        "Then, df['statement'] = df['statement'].apply(remove_patterns) applies this cleaning function to every statement in the DataFrame.\n",
        "\n",
        "**Inputs:**\n",
        "The input is the statement column in the DataFrame, which already contains lowercase text from the previous preprocessing step.\n",
        "\n",
        "**Outputs:**\n",
        "The output is a cleaned version of the statement column with URLs, punctuation, and special symbols removed.\n",
        "\n",
        "Example:\n",
        "\n",
        "*   Original: “Gr gr dreaming of ex crush to be my game, God”\n",
        "*   Cleaned: “gr gr dreaming of ex crush to be my game god”\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step improves data quality by removing extra symbols and irrelevant content. Clean text helps the model focus only on important words, which is essential for accurate sentiment analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xQ3NLH1qCMWj",
        "outputId": "d6ae470a-6aee-4726-b2d7-2043f26c4bf1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  original_statement  status  \\\n",
              "0      Gr gr dreaming of ex crush to be my game, God  Normal   \n",
              "1                                 wkwkwk what a joke  Normal   \n",
              "2  Leaves are also standby in front of the PC ......  Normal   \n",
              "3     Thank God even though it's just a ride through  Normal   \n",
              "4  wedding teaser concept using the song day6 - o...  Normal   \n",
              "\n",
              "   num_of_characters  num_of_sentences  \\\n",
              "0                 45                 1   \n",
              "1                 18                 1   \n",
              "2                 87                 1   \n",
              "3                 46                 1   \n",
              "4                 71                 1   \n",
              "\n",
              "                                           statement  \n",
              "0       gr gr dreaming of ex crush to be my game god  \n",
              "1                                 wkwkwk what a joke  \n",
              "2  leaves are also standby in front of the pc  be...  \n",
              "3      thank god even though its just a ride through  \n",
              "4  wedding teaser concept using the song day6  on...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3118c0b-8bb8-4889-95d3-8c34624bb641\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_statement</th>\n",
              "      <th>status</th>\n",
              "      <th>num_of_characters</th>\n",
              "      <th>num_of_sentences</th>\n",
              "      <th>statement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Gr gr dreaming of ex crush to be my game, God</td>\n",
              "      <td>Normal</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>gr gr dreaming of ex crush to be my game god</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wkwkwk what a joke</td>\n",
              "      <td>Normal</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>wkwkwk what a joke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Leaves are also standby in front of the PC ......</td>\n",
              "      <td>Normal</td>\n",
              "      <td>87</td>\n",
              "      <td>1</td>\n",
              "      <td>leaves are also standby in front of the pc  be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Thank God even though it's just a ride through</td>\n",
              "      <td>Normal</td>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>thank god even though its just a ride through</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wedding teaser concept using the song day6 - o...</td>\n",
              "      <td>Normal</td>\n",
              "      <td>71</td>\n",
              "      <td>1</td>\n",
              "      <td>wedding teaser concept using the song day6  on...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3118c0b-8bb8-4889-95d3-8c34624bb641')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e3118c0b-8bb8-4889-95d3-8c34624bb641 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e3118c0b-8bb8-4889-95d3-8c34624bb641');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-af747b71-e15e-4faf-a318-f72ec790bb9d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-af747b71-e15e-4faf-a318-f72ec790bb9d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-af747b71-e15e-4faf-a318-f72ec790bb9d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 26995,\n  \"fields\": [\n    {\n      \"column\": \"original_statement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26683,\n        \"samples\": [\n          \"I have been here long enough and I am ready to leave now, I am not young so my dearh will not be a tragedy. I have had enough of my pathetic existence. I am thinking of going through with it next week, I wonder how long it takes to actually die from hanging... When do I get to die?\",\n          \"i honestly do not know how much longer i can go. I have attempted many times in the past by overdosing but sadly survived. one of the biggest reasons why I am still here is, bc i do not want my parents to have to bury me. i do not want to pass my pain onto others, but i really do not have much left in me. i have dreams &amp; goals, but they seem so impossible with depression draining me, &amp; suicide on my mind 24/7. I have been to the psych ward many times, tried many different medications, &amp; have seen therapists. my friends &amp; family are supportive, but they really do not understand. i just wish i was already gone. cannot keep going\",\n          \"in the photoshop\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Suicidal\",\n          \"Normal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_of_characters\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 699,\n        \"min\": 2,\n        \"max\": 32759,\n        \"num_unique_values\": 2385,\n        \"samples\": [\n          4043,\n          5845\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_of_sentences\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 1,\n        \"max\": 1260,\n        \"num_unique_values\": 90,\n        \"samples\": [\n          61,\n          30\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"statement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26589,\n        \"samples\": [\n          \"i made a decision that i had enough of this fear and i was going to die fighting and not be afraid anymore i reached this point a few years ago it is a wonderful thing to sleep peacefully i was tired of wanting to sleep in my trunk in my car in my garage because i was afraid of sleeping alone in houses i was tired of sleeping on the sofa or on the floor of different rooms just to avoid sleeping in bedrooms because of fear\",\n          \"so do i but im worried\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "def remove_patterns(text):\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
        "    # Remove markdown-style links\n",
        "    text = re.sub(r'\\[.*?\\]\\(.*?\\)', '', text)\n",
        "    # Remove handles (that start with '@')\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    # Remove punctuation and other special characters\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text.strip()\n",
        "\n",
        "# Apply the function to the 'statement' column\n",
        "df['statement'] = df['statement'].apply(remove_patterns)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2Wz9lKrCdmY"
      },
      "source": [
        "### 3.3. Removing Stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrtqstvO2A2e"
      },
      "source": [
        "**Function Description:**\n",
        "This code removes stopwords, which are common words such as “the,” “is,” “in,” and “of” that do not carry important meaning for sentiment analysis. Removing them helps the model focus on the more meaningful words in each statement.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The function remove_stopwords(text) first loads a list of common English stopwords using stopwords.words('english'). Then, it splits the text into individual words using word_tokenize(text). A list comprehension filters out the words that appear in the stopwords list. Finally, ' '.join(filtered_words) combines the remaining words back into a clean sentence.\n",
        "The line df['statement'] = df['statement'].apply(remove_stopwords) applies this function to every entry in the statement column.\n",
        "\n",
        "**Inputs:**\n",
        "The input is the cleaned statement column, which no longer contains punctuation, special characters, or URLs.\n",
        "\n",
        "**Outputs:**\n",
        "The output is an updated statement column with stopwords removed.\n",
        "\n",
        "Example:\n",
        "\n",
        "*   Original: “Gr gr dreaming of ex crush to be my game, God”\n",
        "*   Cleaned: “gr gr dreaming ex crush game god”\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step makes the text data cleaner and more focused by removing words that add little meaning. It improves the model’s ability to detect emotional or suicidal expressions by emphasizing key words that reflect intent or mental state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0QhI4KrkERqG",
        "outputId": "62fa320f-c6c4-4f81-ff48-4eb8492f160d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  original_statement  status  \\\n",
              "0      Gr gr dreaming of ex crush to be my game, God  Normal   \n",
              "1                                 wkwkwk what a joke  Normal   \n",
              "2  Leaves are also standby in front of the PC ......  Normal   \n",
              "3     Thank God even though it's just a ride through  Normal   \n",
              "4  wedding teaser concept using the song day6 - o...  Normal   \n",
              "\n",
              "   num_of_characters  num_of_sentences  \\\n",
              "0                 45                 1   \n",
              "1                 18                 1   \n",
              "2                 87                 1   \n",
              "3                 46                 1   \n",
              "4                 71                 1   \n",
              "\n",
              "                                           statement  \n",
              "0                   gr gr dreaming ex crush game god  \n",
              "1                                        wkwkwk joke  \n",
              "2   leaves also standby front pc office longer leave  \n",
              "3                         thank god even though ride  \n",
              "4  wedding teaser concept using song day6 sounds ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bda20d16-1ee8-4bff-992e-1265ce786b57\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_statement</th>\n",
              "      <th>status</th>\n",
              "      <th>num_of_characters</th>\n",
              "      <th>num_of_sentences</th>\n",
              "      <th>statement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Gr gr dreaming of ex crush to be my game, God</td>\n",
              "      <td>Normal</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>gr gr dreaming ex crush game god</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wkwkwk what a joke</td>\n",
              "      <td>Normal</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>wkwkwk joke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Leaves are also standby in front of the PC ......</td>\n",
              "      <td>Normal</td>\n",
              "      <td>87</td>\n",
              "      <td>1</td>\n",
              "      <td>leaves also standby front pc office longer leave</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Thank God even though it's just a ride through</td>\n",
              "      <td>Normal</td>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>thank god even though ride</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wedding teaser concept using the song day6 - o...</td>\n",
              "      <td>Normal</td>\n",
              "      <td>71</td>\n",
              "      <td>1</td>\n",
              "      <td>wedding teaser concept using song day6 sounds ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bda20d16-1ee8-4bff-992e-1265ce786b57')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bda20d16-1ee8-4bff-992e-1265ce786b57 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bda20d16-1ee8-4bff-992e-1265ce786b57');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0b84b235-4ce7-4966-a5f3-631d41ae7bd1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b84b235-4ce7-4966-a5f3-631d41ae7bd1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0b84b235-4ce7-4966-a5f3-631d41ae7bd1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 26995,\n  \"fields\": [\n    {\n      \"column\": \"original_statement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26683,\n        \"samples\": [\n          \"I have been here long enough and I am ready to leave now, I am not young so my dearh will not be a tragedy. I have had enough of my pathetic existence. I am thinking of going through with it next week, I wonder how long it takes to actually die from hanging... When do I get to die?\",\n          \"i honestly do not know how much longer i can go. I have attempted many times in the past by overdosing but sadly survived. one of the biggest reasons why I am still here is, bc i do not want my parents to have to bury me. i do not want to pass my pain onto others, but i really do not have much left in me. i have dreams &amp; goals, but they seem so impossible with depression draining me, &amp; suicide on my mind 24/7. I have been to the psych ward many times, tried many different medications, &amp; have seen therapists. my friends &amp; family are supportive, but they really do not understand. i just wish i was already gone. cannot keep going\",\n          \"in the photoshop\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Suicidal\",\n          \"Normal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_of_characters\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 699,\n        \"min\": 2,\n        \"max\": 32759,\n        \"num_unique_values\": 2385,\n        \"samples\": [\n          4043,\n          5845\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_of_sentences\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 1,\n        \"max\": 1260,\n        \"num_unique_values\": 90,\n        \"samples\": [\n          61,\n          30\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"statement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26210,\n        \"samples\": [\n          \"done everything right worked hard get constantly feel like something missing like life incomplete feel like something missing\",\n          \"family loves close friends even means got alright college despite think killing makes feel like spoiled piece shit leads hating makes want die repeats cycle wish life shit would feel bad wanting kill\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Define function to remove stopwords\n",
        "def remove_stopwords(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = word_tokenize(text)\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "# Apply the function to the 'statement' column\n",
        "df['statement'] = df['statement'].apply(remove_stopwords)\n",
        "\n",
        "# Display the cleaned data\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p6pKb8PCTDF"
      },
      "source": [
        "### 3.4. Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GaJeB2p2UW8"
      },
      "source": [
        "**Function Description:**\n",
        "This part of the code breaks each statement into smaller pieces called tokens, usually words. Tokenization helps the model understand each word separately instead of reading the text as one long string.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The function word_tokenize from NLTK splits each sentence into individual words or tokens. The line df['tokens'] = df['statement'].apply(word_tokenize) applies this tokenizer to every entry in the statement column and stores the result in a new column called tokens.\n",
        "\n",
        "**Inputs:**\n",
        "The input is the cleaned statement column that has already been lowercased and stripped of stopwords, URLs, and punctuation.\n",
        "\n",
        "**Outputs:**\n",
        "The output is a new column called tokens containing lists of words for each statement.\n",
        "\n",
        "Example:\n",
        "\n",
        "*   Original: “Gr gr dreaming of ex crush to be my game, God”\n",
        "*   Tokenized: [gr, gr, dreaming, ex, crush, game, god]\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step turns each sentence into a sequence of words, which is essential for most natural language processing (NLP) tasks. It prepares the data for later stages such as stemming, lemmatization, or model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "jkX21RlECUDB",
        "outputId": "d3f3d6eb-9fd6-4c86-9eb9-8cebce100147"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  original_statement  status  \\\n",
              "0      Gr gr dreaming of ex crush to be my game, God  Normal   \n",
              "1                                 wkwkwk what a joke  Normal   \n",
              "2  Leaves are also standby in front of the PC ......  Normal   \n",
              "3     Thank God even though it's just a ride through  Normal   \n",
              "4  wedding teaser concept using the song day6 - o...  Normal   \n",
              "\n",
              "   num_of_characters  num_of_sentences  \\\n",
              "0                 45                 1   \n",
              "1                 18                 1   \n",
              "2                 87                 1   \n",
              "3                 46                 1   \n",
              "4                 71                 1   \n",
              "\n",
              "                                           statement  \\\n",
              "0                   gr gr dreaming ex crush game god   \n",
              "1                                        wkwkwk joke   \n",
              "2   leaves also standby front pc office longer leave   \n",
              "3                         thank god even though ride   \n",
              "4  wedding teaser concept using song day6 sounds ...   \n",
              "\n",
              "                                              tokens  \n",
              "0           [gr, gr, dreaming, ex, crush, game, god]  \n",
              "1                                     [wkwkwk, joke]  \n",
              "2  [leaves, also, standby, front, pc, office, lon...  \n",
              "3                   [thank, god, even, though, ride]  \n",
              "4  [wedding, teaser, concept, using, song, day6, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6657fb3-abe0-498e-b9ce-dbde0009541b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_statement</th>\n",
              "      <th>status</th>\n",
              "      <th>num_of_characters</th>\n",
              "      <th>num_of_sentences</th>\n",
              "      <th>statement</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Gr gr dreaming of ex crush to be my game, God</td>\n",
              "      <td>Normal</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>gr gr dreaming ex crush game god</td>\n",
              "      <td>[gr, gr, dreaming, ex, crush, game, god]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wkwkwk what a joke</td>\n",
              "      <td>Normal</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>wkwkwk joke</td>\n",
              "      <td>[wkwkwk, joke]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Leaves are also standby in front of the PC ......</td>\n",
              "      <td>Normal</td>\n",
              "      <td>87</td>\n",
              "      <td>1</td>\n",
              "      <td>leaves also standby front pc office longer leave</td>\n",
              "      <td>[leaves, also, standby, front, pc, office, lon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Thank God even though it's just a ride through</td>\n",
              "      <td>Normal</td>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>thank god even though ride</td>\n",
              "      <td>[thank, god, even, though, ride]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wedding teaser concept using the song day6 - o...</td>\n",
              "      <td>Normal</td>\n",
              "      <td>71</td>\n",
              "      <td>1</td>\n",
              "      <td>wedding teaser concept using song day6 sounds ...</td>\n",
              "      <td>[wedding, teaser, concept, using, song, day6, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6657fb3-abe0-498e-b9ce-dbde0009541b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a6657fb3-abe0-498e-b9ce-dbde0009541b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a6657fb3-abe0-498e-b9ce-dbde0009541b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8e5d18f9-f8ba-48a0-883f-66f65987e107\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8e5d18f9-f8ba-48a0-883f-66f65987e107')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8e5d18f9-f8ba-48a0-883f-66f65987e107 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 26995,\n  \"fields\": [\n    {\n      \"column\": \"original_statement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26683,\n        \"samples\": [\n          \"I have been here long enough and I am ready to leave now, I am not young so my dearh will not be a tragedy. I have had enough of my pathetic existence. I am thinking of going through with it next week, I wonder how long it takes to actually die from hanging... When do I get to die?\",\n          \"i honestly do not know how much longer i can go. I have attempted many times in the past by overdosing but sadly survived. one of the biggest reasons why I am still here is, bc i do not want my parents to have to bury me. i do not want to pass my pain onto others, but i really do not have much left in me. i have dreams &amp; goals, but they seem so impossible with depression draining me, &amp; suicide on my mind 24/7. I have been to the psych ward many times, tried many different medications, &amp; have seen therapists. my friends &amp; family are supportive, but they really do not understand. i just wish i was already gone. cannot keep going\",\n          \"in the photoshop\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Suicidal\",\n          \"Normal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_of_characters\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 699,\n        \"min\": 2,\n        \"max\": 32759,\n        \"num_unique_values\": 2385,\n        \"samples\": [\n          4043,\n          5845\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_of_sentences\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 1,\n        \"max\": 1260,\n        \"num_unique_values\": 90,\n        \"samples\": [\n          61,\n          30\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"statement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26210,\n        \"samples\": [\n          \"done everything right worked hard get constantly feel like something missing like life incomplete feel like something missing\",\n          \"family loves close friends even means got alright college despite think killing makes feel like spoiled piece shit leads hating makes want die repeats cycle wish life shit would feel bad wanting kill\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Apply word_tokenize to each element in the 'statement' column\n",
        "df['tokens'] = df['statement'].apply(word_tokenize)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22Jlt7xxCjw9"
      },
      "source": [
        "### 3.5. Lemmatization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I9n5WoB282w"
      },
      "source": [
        "**Function Description:**\n",
        "This code performs lemmatization, which means reducing words to their base or dictionary form (for example, “running” becomes “run” and “better” becomes “good”). Lemmatization helps the model treat similar words as one, improving consistency in text analysis.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The function lemmatize_text(text) first creates a lemmatizer using WordNetLemmatizer(). It then splits the text into individual words using word_tokenize(text). Each word is lemmatized and converted to lowercase inside a list comprehension. Finally, the words are joined back into a clean sentence using ' '.join(lemmatized_words).\n",
        "The line df['statement'] = df['statement'].apply(lemmatize_text) applies this process to every statement in the dataset.\n",
        "\n",
        "**Inputs:**\n",
        "The input is the cleaned statement column containing lowercased and tokenized text without stopwords or special characters.\n",
        "\n",
        "**Outputs:**\n",
        "The output is an updated statement column where each word is replaced with its lemmatized (base) form.\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step differs from tokenization because tokenization only splits text into words, while lemmatization transforms each word into its simplest form. Lemmatization makes the dataset more uniform, helping the model recognize patterns in word meaning rather than just surface forms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "3eGKwJUTE3mx",
        "outputId": "857f2efd-b5e2-481d-ef94-b5648988ed40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  original_statement  status  \\\n",
              "0      Gr gr dreaming of ex crush to be my game, God  Normal   \n",
              "1                                 wkwkwk what a joke  Normal   \n",
              "2  Leaves are also standby in front of the PC ......  Normal   \n",
              "3     Thank God even though it's just a ride through  Normal   \n",
              "4  wedding teaser concept using the song day6 - o...  Normal   \n",
              "\n",
              "   num_of_characters  num_of_sentences  \\\n",
              "0                 45                 1   \n",
              "1                 18                 1   \n",
              "2                 87                 1   \n",
              "3                 46                 1   \n",
              "4                 71                 1   \n",
              "\n",
              "                                           statement  \\\n",
              "0                   gr gr dreaming ex crush game god   \n",
              "1                                        wkwkwk joke   \n",
              "2     leaf also standby front pc office longer leave   \n",
              "3                         thank god even though ride   \n",
              "4  wedding teaser concept using song day6 sound g...   \n",
              "\n",
              "                                              tokens  \n",
              "0           [gr, gr, dreaming, ex, crush, game, god]  \n",
              "1                                     [wkwkwk, joke]  \n",
              "2  [leaves, also, standby, front, pc, office, lon...  \n",
              "3                   [thank, god, even, though, ride]  \n",
              "4  [wedding, teaser, concept, using, song, day6, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-727f2121-5cfe-4456-ade8-4ed4f8795d4d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_statement</th>\n",
              "      <th>status</th>\n",
              "      <th>num_of_characters</th>\n",
              "      <th>num_of_sentences</th>\n",
              "      <th>statement</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Gr gr dreaming of ex crush to be my game, God</td>\n",
              "      <td>Normal</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>gr gr dreaming ex crush game god</td>\n",
              "      <td>[gr, gr, dreaming, ex, crush, game, god]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wkwkwk what a joke</td>\n",
              "      <td>Normal</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>wkwkwk joke</td>\n",
              "      <td>[wkwkwk, joke]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Leaves are also standby in front of the PC ......</td>\n",
              "      <td>Normal</td>\n",
              "      <td>87</td>\n",
              "      <td>1</td>\n",
              "      <td>leaf also standby front pc office longer leave</td>\n",
              "      <td>[leaves, also, standby, front, pc, office, lon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Thank God even though it's just a ride through</td>\n",
              "      <td>Normal</td>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>thank god even though ride</td>\n",
              "      <td>[thank, god, even, though, ride]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wedding teaser concept using the song day6 - o...</td>\n",
              "      <td>Normal</td>\n",
              "      <td>71</td>\n",
              "      <td>1</td>\n",
              "      <td>wedding teaser concept using song day6 sound g...</td>\n",
              "      <td>[wedding, teaser, concept, using, song, day6, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-727f2121-5cfe-4456-ade8-4ed4f8795d4d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-727f2121-5cfe-4456-ade8-4ed4f8795d4d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-727f2121-5cfe-4456-ade8-4ed4f8795d4d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6a2718c1-fe57-4f39-a774-c48ad252309f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6a2718c1-fe57-4f39-a774-c48ad252309f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6a2718c1-fe57-4f39-a774-c48ad252309f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 26995,\n  \"fields\": [\n    {\n      \"column\": \"original_statement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26683,\n        \"samples\": [\n          \"I have been here long enough and I am ready to leave now, I am not young so my dearh will not be a tragedy. I have had enough of my pathetic existence. I am thinking of going through with it next week, I wonder how long it takes to actually die from hanging... When do I get to die?\",\n          \"i honestly do not know how much longer i can go. I have attempted many times in the past by overdosing but sadly survived. one of the biggest reasons why I am still here is, bc i do not want my parents to have to bury me. i do not want to pass my pain onto others, but i really do not have much left in me. i have dreams &amp; goals, but they seem so impossible with depression draining me, &amp; suicide on my mind 24/7. I have been to the psych ward many times, tried many different medications, &amp; have seen therapists. my friends &amp; family are supportive, but they really do not understand. i just wish i was already gone. cannot keep going\",\n          \"in the photoshop\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Suicidal\",\n          \"Normal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_of_characters\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 699,\n        \"min\": 2,\n        \"max\": 32759,\n        \"num_unique_values\": 2385,\n        \"samples\": [\n          4043,\n          5845\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_of_sentences\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 1,\n        \"max\": 1260,\n        \"num_unique_values\": 90,\n        \"samples\": [\n          61,\n          30\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"statement\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26200,\n        \"samples\": [\n          \"suffered serve anxiety ever since 17 year old diagnosed depression 18 somehow managed beat back anxiety never left ever since learned manage 23 year old trying get parent shelter unlike lot people believe problem people general might say statement simple word mean problem believe anymore lot dark thought past 5 year seems back contemplating suicide lot lately thing hold back family want hurt parent younger sibling know would devastating themi ashamed making parent proud good role model sibling crybaby subreddit feel hopeless lost good friend hardly relationship lasted longer 3 month cheated betrayed people even best friend considered brother like everything happened left got conclusion world full egoism narcissism cinism think trying good person never work world full hate full people whose intention fucking destroy people think nothing left absolutely nothing keep living circumstance live among people feel stranger everyone tired tired holding tired keeping thing inside tired hanging around people acting like cry every night day two goddamn month leaving need see bright day ffs cruel tired\",\n          \"somedays easier others somedays want suicide knowing know fail time day think exist nt broke waste away life 100502525 amount swallowed number look haunt ever pray feeling existing someone world tearsrun face wonder much take much belittle fulfill one desire body make 4 month since attempting commit suicide\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Define function for lemmatization\n",
        "def lemmatize_text(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = word_tokenize(text)\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word.lower()) for word in words]\n",
        "    return ' '.join(lemmatized_words)\n",
        "\n",
        "# Apply the function to the 'statement' column\n",
        "df['statement'] = df['statement'].apply(lemmatize_text)\n",
        "\n",
        "# Display the cleaned data\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwr87q4eFUoo"
      },
      "source": [
        "# **4. Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjAjqgIjFeDb"
      },
      "source": [
        "### 4.1. Separate features and labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JgBScPF3aBb"
      },
      "source": [
        "**Function Description:**\n",
        "This code separates the dataset into features (X) and labels (y), which is a key step before training a machine learning model. Features are the input variables used to make predictions, while labels are the target values the model tries to predict.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The line X = df[['statement', 'num_of_characters', 'num_of_sentences']] selects the columns that will serve as input features. These include the cleaned text (statement) and two numerical features: num_of_characters and num_of_sentences.\n",
        "The line y = df['status'] assigns the status column as the target label, representing whether a statement is Normal or Suicidal.\n",
        "\n",
        "**Inputs:**\n",
        "The input is the cleaned and preprocessed dataset containing both text and numerical features.\n",
        "\n",
        "**Outputs:**\n",
        "The output is two separate variables: X, which contains the input features used for model training, and y, which contains the target labels indicating the sentiment status.\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step prepares the data for machine learning. By including both text and numerical features, the model can consider not just the words used but also the length and structure of each statement when detecting mental health–related sentiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rFbca1IFdyV"
      },
      "outputs": [],
      "source": [
        "X = df[['statement', 'num_of_characters', 'num_of_sentences']]\n",
        "y = df['status']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgCQbZJ-Fuh0"
      },
      "source": [
        "### 4.2. Label encoding target variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbGfb2Wc3p6a"
      },
      "source": [
        "**Function Description:**\n",
        "This code converts the categorical text labels in the target variable (y) into numeric values that machine learning models can understand. Since most models work with numbers, encoding text labels is a necessary step.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The line lbl_enc = LabelEncoder() creates an instance of the LabelEncoder class from scikit-learn. This tool assigns a unique number to each category.\n",
        "The line y = lbl_enc.fit_transform(y.values) fits the encoder to the existing labels (Normal and Suicidal) and transforms them into numeric form—typically 0 and 1.\n",
        "\n",
        "**Inputs:**\n",
        "The input is the y variable containing categorical sentiment labels: “Normal” and “Suicidal.”\n",
        "\n",
        "**Outputs:**\n",
        "The output is a transformed y variable with numeric labels, where each category is represented by an integer (for example, 0 for Normal and 1 for Suicidal).\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step ensures that the machine learning model can correctly process the target labels. Encoding categorical data helps the model compare and compute results efficiently during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fG93xPmxF8_O"
      },
      "outputs": [],
      "source": [
        "lbl_enc = LabelEncoder()\n",
        "y = lbl_enc.fit_transform(y.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnHRF4OzF_au"
      },
      "source": [
        "### 4.3. Split the data into training and testing sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky8yJN5g30Ur"
      },
      "source": [
        "**Function Description:**\n",
        "This code divides the dataset into two parts: a training set and a testing set. The training set is used to teach the model how to identify patterns, while the testing set is used to check how well the model performs on unseen data.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The line X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101) uses the train_test_split function from scikit-learn.\n",
        "Here, X contains the features and y contains the labels. The parameter test_size=0.2 means that 20% of the data will be used for testing and 80% for training. The random_state=101 ensures that the split is the same every time the code is run, allowing for consistent results.\n",
        "\n",
        "**Inputs:**\n",
        "The inputs are the feature set X and the encoded label set y.\n",
        "\n",
        "**Outputs:**\n",
        "The output is four new variables: X_train and y_train for training the model, and X_test and y_test for evaluating it.\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step is important for testing the model’s ability to generalize. By separating the data, the model can be evaluated on data it has never seen before, helping ensure that the predictions are reliable and not just memorized patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzSQY7noGCGK"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TF7NMtYGFk8"
      },
      "source": [
        "### 4.4. Convert text to features using TF-IDF vectoriser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a2gh0CM4H00"
      },
      "source": [
        "**Function Description:**\n",
        "This code changes the text data into numbers using TF-IDF (Term Frequency–Inverse Document Frequency) and combines it with other numeric features. TF-IDF helps the model find which words are most important in each statement by looking at how often they appear.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The line vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=50000) creates a TF-IDF vectorizer that looks at single words and pairs of words, keeping only the top 50,000 features. The line vectorizer.fit_transform(X_train['statement']) learns the words from the training text and turns them into numbers, while vectorizer.transform(X_test['statement']) applies the same process to the test text. The next lines take the numerical features (num_of_characters and num_of_sentences) from both the training and test sets using .values. Finally, hstack([X_train_tfidf, X_train_num]) and hstack([X_test_tfidf, X_test_num]) combine the TF-IDF features with the numeric features to make the full datasets for training and testing.\n",
        "\n",
        "**Inputs:**\n",
        "The inputs are the statement column and the numeric features num_of_characters and num_of_sentences from both the training and test sets.\n",
        "\n",
        "**Outputs:**\n",
        "The output is two combined datasets, X_train_combined and X_test_combined, which include both text and numeric features. The printed output shows that 50,000 feature words were used.\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step prepares the data so the model can understand both text and numbers. It helps the model learn not just from word meanings but also from how long or complex each statement is, which can improve accuracy when analyzing mental health–related text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCmTZyMxGJoT",
        "outputId": "b9557e1f-4934-400f-b554-ed9717d02b15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of feature words:  50000\n"
          ]
        }
      ],
      "source": [
        "# 1. Initialize TF-IDF Vectorizer and fit/transform on the 'tokens' column\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=50000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train['statement'])\n",
        "X_test_tfidf = vectorizer.transform(X_test['statement'])\n",
        "\n",
        "# 2. Extract numerical features\n",
        "X_train_num = X_train[['num_of_characters', 'num_of_sentences']].values\n",
        "X_test_num = X_test[['num_of_characters', 'num_of_sentences']].values\n",
        "\n",
        "# 3. Combine TF-IDF features with numerical features\n",
        "X_train_combined = hstack([X_train_tfidf, X_train_num])\n",
        "X_test_combined = hstack([X_test_tfidf, X_test_num])\n",
        "\n",
        "print('Number of feature words: ', len(vectorizer.get_feature_names_out()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2l_DiS44ioi"
      },
      "source": [
        "**Function Description:**\n",
        "This code checks the shape or size of the training data after combining the TF-IDF and numeric features. It shows how many samples and features are now included in the dataset.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The line X_train_combined.shape returns a tuple showing two values: the number of rows (data samples) and the number of columns (features).\n",
        "\n",
        "**Inputs:**\n",
        "The input is the combined training dataset X_train_combined that contains both TF-IDF and numeric features.\n",
        "\n",
        "**Outputs:**\n",
        "The output shows the shape of the dataset: (21596, 50002), meaning there are 21,596 training samples and 50,002 total features.\n",
        "\n",
        "**Comments and Observations:**\n",
        "This confirms that the training data was successfully combined. The large number of features (50,002) shows that the text data provides most of the information, with two extra columns for the numeric features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-9AIVbCGLoS",
        "outputId": "d9312e6c-6b67-4161-ced3-b2fd40c7713a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21596, 50002)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "X_train_combined.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE3VDNTrGR8m"
      },
      "source": [
        "### 4.5. Resampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DGiE0xv4q6y"
      },
      "source": [
        "**Function Description:**\n",
        "This code balances the training data by using Random Over-Sampling, a technique that increases the number of samples in the smaller class so that both classes have the same amount. This helps the model learn from both classes equally and prevents bias toward the majority class.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The line ros = RandomOverSampler(random_state=101) creates a RandomOverSampler object, which will randomly duplicate samples from the minority class.\n",
        "The line X_train_resampled, y_train_resampled = ros.fit_resample(X_train_combined, y_train) applies this technique to the training data, creating new balanced versions of X_train_combined and y_train.\n",
        "\n",
        "**Inputs:**\n",
        "The inputs are X_train_combined, which contains the training features, and y_train, which contains the corresponding labels.\n",
        "\n",
        "**Outputs:**\n",
        "The output is a balanced version of the training data, stored in X_train_resampled and y_train_resampled, where both classes now have an equal number of samples.\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step improves model fairness and accuracy by making sure it learns equally from both “Normal” and “Suicidal” statements. It helps prevent the model from favoring the more common class during prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qAqquVIGQer"
      },
      "outputs": [],
      "source": [
        "# Apply Random Over-Sampling on the vectorized data\n",
        "ros = RandomOverSampler(random_state=101)\n",
        "X_train_resampled, y_train_resampled = ros.fit_resample(X_train_combined, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxhSpu-T4_rV"
      },
      "source": [
        "**Function Description:**\n",
        "This code checks the shape or dimensions of the resampled training dataset to confirm that the Random Over-Sampling process was successful.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The line X_train_resampled.shape returns a pair of numbers showing how many samples (rows) and features (columns) are in the dataset after balancing.\n",
        "\n",
        "**Inputs:**\n",
        "The input is the resampled training data, X_train_resampled, which contains the balanced features for both classes.\n",
        "\n",
        "**Outputs:**\n",
        "The output is (26208, 50002), meaning the resampled training set now has 26,208 samples and 50,002 features.\n",
        "\n",
        "**Comments and Observations:**\n",
        "This confirms that the training data is now balanced. The number of samples increased from the original dataset because the minority class was duplicated to match the majority class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe6mQUZsGUBw",
        "outputId": "db1af0c1-dd0d-4d00-824d-a42bbb8df05a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26208, 50002)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "X_train_resampled.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0Bol3575VT4"
      },
      "source": [
        "**Function Description:**\n",
        "This code converts the text-based class labels into numeric form so that the machine learning model can process them. Encoding labels is important because most algorithms can only work with numerical data.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The line le = LabelEncoder() creates an instance of the LabelEncoder from scikit-learn.\n",
        "The line y_train_encoded = le.fit_transform(y_train) fits the encoder to the training labels and transforms them into numbers.\n",
        "The line y_test_encoded = le.transform(y_test) applies the same encoding to the test labels, ensuring both sets use the same label mapping.\n",
        "\n",
        "**Inputs:**\n",
        "The inputs are the original training and testing label sets, y_train and y_test, which contain categorical values like “Normal” and “Suicidal.”\n",
        "\n",
        "**Outputs:**\n",
        "The outputs are y_train_encoded and y_test_encoded, which contain numeric labels (for example, 0 for Normal and 1 for Suicidal).\n",
        "\n",
        "**Comments and Observations:**\n",
        "This step prepares the label data for modeling. Using numeric values ensures that both the training and testing data follow the same label structure, allowing for consistent evaluation of the model’s predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf5ESZqeGVyK"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode target labels\n",
        "le = LabelEncoder()\n",
        "y_train_encoded = le.fit_transform(y_train)\n",
        "y_test_encoded = le.transform(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LPXF72g5efn"
      },
      "source": [
        "**Function Description:**\n",
        "This code saves the cleaned and preprocessed dataset into a CSV file so it can be reused later for modeling, sharing, or further analysis without redoing all the preprocessing steps.\n",
        "\n",
        "**Syntax Explanation:**\n",
        "The function df.to_csv() writes the DataFrame df to a CSV file.\n",
        "The argument \"/content/Cleaned_Combined_Data.csv\" specifies the file path and name of the output file.\n",
        "The parameter index=False means that the row indices will not be included in the saved file, keeping the CSV clean and easier to read.\n",
        "\n",
        "**Inputs:**\n",
        "The input is the final preprocessed DataFrame named df, which contains cleaned text data, tokenized columns, and numerical features.\n",
        "\n",
        "**Outputs:**\n",
        "The output is a CSV file named “Cleaned_Combined_Data.csv” saved in the /content/ directory.\n",
        "\n",
        "**Comments and Observations:**\n",
        "The dataset has been successfully exported and can now be easily loaded for further steps like model training or validation. This ensures data consistency and saves time when repeating experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oK26nDl8NNR1"
      },
      "outputs": [],
      "source": [
        "# Exporting cleaned data into .csv file\n",
        "\n",
        "df.to_csv(\"/content/Cleaned_Combined_Data.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyFuHDhOEx4r"
      },
      "source": [
        "# **FINE-TUNING MODEL**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aJwEkL29VS9"
      },
      "source": [
        "## **1. Setup and Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pTiH3ln9SMN",
        "outputId": "248f4cba-5447-404c-fda3-e6e1410d4a19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets torch sklearn -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I started by installing the core libraries needed to work with `transformer-based` models, especially since I’ll be using MentalBERT later on for sentiment analysis. The transformers library gives access to a wide range of pre-trained NLP models and tools for tokenization, fine-tuning, and text generation. It’s basically the foundation that allows me to load and use advanced models without having to train them from scratch.\n",
        "\n",
        "The `datasets` library helps in handling large text datasets more efficiently. It makes it easy to load, split, and preprocess data, which is really useful when preparing text for BERT-based models. Meanwhile, I installed `torch` because it’s the deep learning framework that powers these transformer models  it handles all the computations that happen behind the scenes during model training and prediction.\n",
        "\n",
        "Lastly, I added `sklearn` since it includes tools for model evaluation and preprocessing that I’ll still use alongside the transformer model. Adding the `-q` flag just runs the installation quietly, so it doesn’t flood the notebook with too much text output. Overall, this setup ensures that everything I need for deep learning and NLP is ready before I start working with MentalBERT."
      ],
      "metadata": {
        "id": "_8wrtzD-XoZl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "8cd546fd15404f6694b908a31cfeaed9",
            "338d8e3514864fb79a7faa73026e5cb0",
            "0f93b9f3e221448089e1ae75c00f3efd",
            "2cf85998dc72431aa274613c67d2881c",
            "eca6135b9bff492292bd3675af43cdae",
            "2adb54e954b24531ae42f04f36485e1d",
            "f8bb0f6f4dcc40da910240e5c5267064",
            "801cf27204ca4c73a8ddf4cee18781e8",
            "97e817ae9f7d4437a113bc0a2850d377",
            "f8792bc8609a44dfa012993490c35585",
            "b0009f1ec9f34553ad5a0c5978badbc0",
            "878fa955c09f4f3890652f1c448dc12c",
            "6da317d27d3a46538edc4f7eac3a7540",
            "04b1057a74054c43821aab5ba75fe0ac",
            "9f129ea9610f464fa07c4456fd5cba66",
            "4026c801e49e4eb59c7133d74701f9b9",
            "b0f3311b6a5f4ea0824bb8ec873888f9",
            "3f72c844066149a9b06ca9d5de3c76e5",
            "126909b954eb4e8e9f8d0f007c58818e",
            "15dcb20edc284754ab5f191e77be8902"
          ]
        },
        "id": "iLSMqvvN9q1E",
        "outputId": "c7ec5218-1ab2-490a-af07-149efab6be2d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8cd546fd15404f6694b908a31cfeaed9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before using **MentalBERT**, I needed to log in to the Hugging Face Hub since this model requires an API token for access. Hugging Face hosts a lot of pre-trained models, including MentalBERT, and it uses authentication to manage who can download and use them. To get this token, I created a free Hugging Face account, went to my profile settings, and generated an access token from the “Access Tokens” section.\n",
        "\n",
        "Once I had the token, I imported the login function from `huggingface_hub` and ran `login()`. This command opens a prompt where I entered my token, which then authenticates my session with the Hugging Face Hub. After logging in, I could securely load the MentalBERT model and its tokenizer without any permission issues."
      ],
      "metadata": {
        "id": "RN9LgvzpX_9s"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAGIN27k5jjR"
      },
      "source": [
        "### MentalBertAPI KEY : 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"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEcfeOXp9235",
        "outputId": "9a6150cd-e430-43a6-c352-7b56c6ab3eae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7t9BO2R69622",
        "outputId": "041ddeeb-dbf8-4e86-928f-b465450f57a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n"
          ]
        }
      ],
      "source": [
        "pip install torch transformers scikit-learn pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used this command to make sure the Transformers library is updated to its latest version. By adding the `-U` flag, it upgrades any older installation instead of just reinstalling the same one. This is important because newer versions of Transformers often include performance improvements, bug fixes, and updated model compatibility  especially when working with models like **MentalBERT** that rely on recent architecture updates.\n",
        "\n",
        "Keeping Transformers up to date ensures that I can use all the latest functions and tokenizer features without running into version conflicts. It also makes sure the library works smoothly with other dependencies like PyTorch and datasets."
      ],
      "metadata": {
        "id": "FoMXw_JOYJ4E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBA-eCjh-yMv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I started by importing all the main libraries needed for preparing, training, and evaluating the MentalBERT model. The `pandas` library is used for handling and exploring the dataset, especially for reading CSV files and managing text data efficiently. Then, I imported `torch` and `Dataset` from PyTorch since Transformers are built on top of it. The `Dataset` class helps convert my text data into a format that can be fed directly into the model during training.\n",
        "\n",
        "Next, I brought in tools from scikit-learn to help with data splitting and evaluation. `train_test_split` divides the dataset into training and testing portions, while `accuracy_score` and `precision_recall_fscore_support` will later help measure how well the model performs on the test data. These metrics give a more complete view of performance, especially for a binary classification task like detecting suicidal vs. normal statements.\n",
        "\n",
        "Finally, I imported everything from Transformers that’s specific to using MentalBERT. `AutoTokenizer` automatically handles tokenization based on the model we choose, converting text into the numerical format BERT understands. `AutoModelForSequenceClassification` loads the actual pre-trained model designed for classification tasks. The `Trainer` and `TrainingArguments` handle the training process  they make it easier to define how the model trains, tracks progress, and saves checkpoints. Together, these imports set up everything I need to fine-tune MentalBERT efficiently."
      ],
      "metadata": {
        "id": "GfeC3JNOYXj7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jndWNJ1H-4gN"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"Cleaned_Combined_Data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I loaded my cleaned dataset using pandas with the `read_csv() `function. This command reads the file named ***“Cleaned_Combined_Data.csv”*** and stores it in a DataFrame called `df`, making it easy to view, filter, and process the data later. This dataset contains the text statements and their corresponding mental health labels that I’ll use to train and test the MentalBERT model."
      ],
      "metadata": {
        "id": "qZg8bt8YY8qg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLST8gsT_AmV"
      },
      "outputs": [],
      "source": [
        "TEXT_COL = \"statement\"\n",
        "LABEL_COL = \"status\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I created two variables, `TEXT_COL and LABEL_COL`, to clearly define which parts of the dataset I’ll be working with. The `TEXT_COL` is set to \"statement\", which holds all the written texts or posts that will be analyzed by the model. The `LABEL_COL` is set to \"status\", which contains the actual categories or mental health conditions  in this case, “Normal” and “Suicidal.”\n",
        "**bold text**\n",
        "Doing this makes my code more organized and easier to maintain. Instead of repeating the column names throughout the code, I can just refer to these variables whenever I need to access the text or the label columns. It’s a simple step, but it helps make the workflow cleaner and less prone to errors, especially when adjusting or reusing the code later on."
      ],
      "metadata": {
        "id": "UbyLHX7YZRms"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAoqaDRp_Dzb",
        "outputId": "1c44114d-6a55-4d96-ceb1-c3483533e7d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Label mapping: {0: 'Normal', 1: 'Suicidal'}\n"
          ]
        }
      ],
      "source": [
        "# Encode string labels to integer IDs\n",
        "df[LABEL_COL] = df[LABEL_COL].astype('category')\n",
        "df['label_id'] = df[LABEL_COL].cat.codes\n",
        "label_mapping = dict(enumerate(df[LABEL_COL].cat.categories))\n",
        "print(\"✅ Label mapping:\", label_mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I converted the string labels in my dataset into numeric values so that the model can understand them. First, I changed the `status` column into a categorical type using `astype('category')`, which helps pandas recognize it as a set of fixed categories instead of plain text. Then, I created a new column called `label_id` using `cat.codes,` which automatically assigns an integer to each category  for example, “Normal” becomes 0 and “Suicidal” becomes 1.\n",
        "\n",
        "I also created a `label_mapping` dictionary to keep track of which number corresponds to which label. This is helpful later when I interpret the model’s predictions and need to translate the results back to readable text. Printing the label mapping confirms that everything was encoded correctly before moving forward with model training."
      ],
      "metadata": {
        "id": "Cpx0uVgGZeY9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rXyAXiY-ibD"
      },
      "outputs": [],
      "source": [
        "# Split dataset\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df[TEXT_COL].tolist(),\n",
        "    df['label_id'].tolist(),\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I split my dataset into training and validation sets using `train_test_split()`. Here, I took the text data from the `statement` column and the numeric labels from the `label_id column`, then separated them into 80% for training and 20% for validation. The `test_size=0.2` means that one-fifth of the data will be used later to check how well the model performs on unseen examples.\n",
        "\n",
        "I also set `random_state=42` to make sure the split stays consistent every time I run the code. This helps with reproducibility, meaning I’ll always get the same training and validation sets across runs. Doing this step ensures that the MentalBERT model will learn from one portion of the data while being tested fairly on another."
      ],
      "metadata": {
        "id": "V8MTH9FkZt-P"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WvglfO-_XY7"
      },
      "source": [
        "## **2. Load Pre-trained Model Definition and Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "1739e9688f3b4c9da39663140820938f",
            "80e791751e934b298438760e88db2748",
            "1d4d72f8ba554b53b15fa64b07aa41b5",
            "f6a5d221e9f2487eac1ecd322cbbf9b9",
            "6bcbfd9568ff40b9925232c29e0adaf1",
            "d29530360caf4d71bbe08eae8e9ac825",
            "637a05a73d2849f09cbfbf7b08c51b3d",
            "8c462caf084e4906ab8cd8689430cd17",
            "3adff7c0065545dd86c98742a4d44367",
            "b63d3c04b85f4c6ab4fb9b90415bcb93",
            "3465561af5b0442b8b89a5f27dda9a66",
            "fe3f4a68fc744807b034b414525578d0",
            "94fd7a463d2846268fb6f83118f2d99c",
            "2ad6e31f2a5f4740b16cdb8471c03038",
            "4ccd9b3287dd44139a041b0a10aa25d0",
            "7e0aab4e440a451ab13c2e774b4c1239",
            "9de78be4010a4b84b084af680f572635",
            "293475acd7594dc386136910299531d8",
            "b30350ef03024a4fa222e02ea5e91265",
            "3eba41b8cdc54b91ba342cb042a6cb2a",
            "408af8f9942c48e593d2351daa9190cb",
            "7e0223e0d45c4828aabc2ee0d80c5a92",
            "329ab9fb8fd24f6197eca526dd697c0d",
            "bc5c942452574ab18514bf7e183318c4",
            "64a19751f6774f99be75de41b4316a72",
            "d5f8c10913774b49a49a52705e39ccb9",
            "832977d5a78a4007abfc850003a0e2bf",
            "6d66ef2b19584b5a8bd54050baa1815b",
            "d202eb9956884f7c83bc4bbcc1090f12",
            "b8f04126130c497c9ed3fe20e8aa1cd5",
            "1ec1d9f566bc4f5fa1e3e2cba56c47c6",
            "bac78f9f43444c7d8b55bf08b78b684f",
            "04ea9840553c499e9aed4bb0de8a07db",
            "bc588ce97cd8443e9b4bc164190b9a85",
            "5afa824e418e42c1bd8e7bb8c9890399",
            "c6e07ea5cd1c463e9942670195b1ba1d",
            "9587ed5e4f8d415895bb470dc945767e",
            "2cf278e7a201486aa5ef70a1a2627a08",
            "df447fc21e6d48869acace53643d26a5",
            "71e2cccc3ee94d20a2712f91bc0371c0",
            "4ec5a7a318b44c1ab7cc306cc58f5f7f",
            "98462e4e027e419b9e2baaea0776d0e9",
            "bae44e9484f44817bfcbe521a790b1a2",
            "37ea01ec381342eeb2493f9bf715ef37"
          ]
        },
        "id": "mC4f98Zw_V7N",
        "outputId": "2e09653c-1085-4c43-d32c-b30ec18162e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/321 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1739e9688f3b4c9da39663140820938f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe3f4a68fc744807b034b414525578d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "329ab9fb8fd24f6197eca526dd697c0d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc588ce97cd8443e9b4bc164190b9a85"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_name = \"mental/mental-bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I set `model_name` to `\"mental/mental-bert-base-uncased\"` since that’s the exact name of the pre-trained **MentalBERT** model I’ll be using from Hugging Face. This model is specifically designed for analyzing mental health–related text, which fits perfectly with my project’s goal of identifying suicidal and normal statements.\n",
        "\n",
        "After that, I loaded the tokenizer using `AutoTokenizer.from_pretrained(model_name)`. The tokenizer is what converts raw text into tokens  basically breaking the text into smaller pieces and turning them into numerical IDs that the model can understand. Using the same tokenizer that comes with the model ensures that the text is processed in the exact way MentalBERT was originally trained."
      ],
      "metadata": {
        "id": "q5lau18-Z5VV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJWlzlcD_hv5"
      },
      "outputs": [],
      "source": [
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=64):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = int(self.labels[idx])\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_len,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I created a custom dataset class called `SentimentDataset`, which inherits from **PyTorch’s** built-in Dataset class. This lets me organize my text and label data in a way that’s compatible with the MentalBERT model during training. Inside the `__init__ `method, I passed in the text data, the corresponding labels, the tokenizer, and a `max_len` parameter (which I set to 64). The `max_len` value limits the maximum number of tokens per input, making sure each text sample has a consistent length for the model to process efficiently.\n",
        "\n",
        "The `__len__` method simply returns how many samples are in the dataset. This is a required method for any PyTorch dataset because it helps the data loader know how many times to loop through the dataset during training. By returning `len(self.texts)`, I’m basically telling the model how many text samples it will be working with.\n",
        "\n",
        "Next, the `__getitem__` method handles how to retrieve each individual sample from the dataset. For each index, it grabs the text and its corresponding label, converts the text into a string, and ensures the label is in integer format. Then, it uses the tokenizer to convert the text into numerical form that the model can understand. Here, I set parameters like `truncation=True `to shorten long texts, `padding=\"max_length\"` to make all sequences the same length, and `return_tensors='pt'` to output the data as PyTorch tensors.\n",
        "\n",
        "Finally, I returned a dictionary containing three key elements: `input_ids, attention_mask,` and `labels`. The input_ids represent the tokenized text, the `attention_mask` tells the model which parts of the input are real words versus padding, and `labels` are the actual target outputs (either Normal or Suicidal). This structure ensures that when the data is loaded in batches, the model receives everything it needs to train"
      ],
      "metadata": {
        "id": "tqV2xxu0aPqE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRf5pa3K_skB"
      },
      "outputs": [],
      "source": [
        "train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\n",
        "val_dataset = SentimentDataset(val_texts, val_labels, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I created two dataset objects  `train_dataset and val_dataset  `using the custom SentimentDataset class I defined earlier. The `train_dataset` contains the training texts and labels that the model will learn from, while the `val_dataset `holds the validation data that will be used to test how well the model performs on unseen samples. Both datasets use the same tokenizer to make sure the text is processed in a consistent way.\n",
        "\n",
        "By passing the text, labels, and tokenizer into the `SentimentDataset` class, each dataset automatically handles tokenization, padding, and truncation for every text entry. This means the data is already preprocessed and ready for **MentalBERT** to use. The dataset structure also makes it easy to load batches of data during training without having to manually tokenize or format the text every time.\n",
        "\n",
        "Splitting the data this way helps prevent overfitting since the model can be trained on one portion of the dataset and validated on another. It’s a clean setup that keeps the workflow organized, ensuring that both training and evaluation use the same processing pipeline and consistent input format."
      ],
      "metadata": {
        "id": "9Jz3SVQJavpA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "6be03ebf22a149148dcb5b32f40f25fb",
            "c831cd93dab74fa4a44caa78262019e2",
            "e92099e5722c47ff858f785ed0a71952",
            "56eedda85f2c4f8dad7698a4c034aa56",
            "792be45444a144e4966c2f3301006662",
            "5bfa81d8d6fb41ee99f06e778683d94a",
            "f06e37e98f674d5e84a935cb6b38e258",
            "bd1c0f05ed5241fda31348894622c24f",
            "30ccbc3a5fba402292d3dc53680b4b5a",
            "cca97ca08ee34d38842305c746eb2053",
            "2e58ff4d62344511a65ee7dafddcbb36",
            "b65af9f22cfc4018bfb22acd7e4b7f72",
            "19d37db1dbdf4b658b1e91584d5cd8e1",
            "fdb5920b6241462fbf326f8c776c765a",
            "2fcdccc2c323431b962cfcef285324bc",
            "82bd638914034dc1b7740f4bab72561d",
            "ea18307990e8481a884bd858872c34c5",
            "3c44ae4f11c34a8ba6e47062ce86b608",
            "eb6330e07b024d85affde02edb51a468",
            "d2d3dd519af94ba58fdc1945f052353b",
            "7dfa7bc90b554f4785ee93c79f00d80d",
            "d2920feb3f924c27a5d8f06913a5f5b3"
          ]
        },
        "id": "Y583MSVB_u_u",
        "outputId": "f24d3c3c-93f8-4c3b-c357-6db9715fd062"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/639 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6be03ebf22a149148dcb5b32f40f25fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b65af9f22cfc4018bfb22acd7e4b7f72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at mental/mental-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "num_labels = len(label_mapping)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I first defined `num_labels` by getting the length of `label_mapping`, which tells me how many unique categories my model needs to predict. Since this project only has two classes — Normal and Suicidal the value of `num_labels` will be 2. Setting this variable ensures that the output layer of the model has the correct number of neurons to match the classification task.\n",
        "\n",
        "Next, I loaded the MentalBERT model using `AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)`. This command downloads the pre-trained MentalBERT weights and automatically configures the model for sequence classification. By including `num_labels`, the final layer is adjusted to handle exactly two output classes.\n",
        "\n",
        "Doing this lets me take advantage of MentalBERT’s pre-trained knowledge on mental health–related text, while still customizing it for my specific task  detecting whether a statement is Normal or Suicidal. It’s an efficient way to use a powerful model that already understands language patterns without having to train one from scratch."
      ],
      "metadata": {
        "id": "UWMoZyHzbD2q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3fBDoda_2i9"
      },
      "outputs": [],
      "source": [
        "# Freeze lower layers for faster fine-tuning\n",
        "for name, param in model.named_parameters():\n",
        "    if not name.startswith(\"classifier\") and not name.startswith(\"bert.encoder.layer.11\"):\n",
        "        param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I decided to **freeze the lower layers of the MentalBERT** model to make fine-tuning faster and more focused. In transformer models like BERT, the lower layers capture general language patterns, while the higher layers and the classifier layer specialize in task-specific features. Since I’m fine-tuning on a relatively small dataset, I don’t need to retrain the entire network from scratch.\n",
        "\n",
        "The `for name, param in model.named_parameters()`: loop goes through all the parameters of the model. By checking the parameter names, I can selectively decide which ones to update during training. Specifically, I keep the classifier layer and the last encoder layer `(bert.encoder.layer.11)` trainable, because these layers are the most important for learning the distinctions between Normal and Suicidal statements.\n",
        "\n",
        "All other parameters have `requires_grad = False`, meaning they won’t be updated during backpropagation. Freezing these layers reduces training time and computational load, while still allowing the model to adjust its final representations to my specific classification task. This is a practical way to fine-tune a large pre-trained model efficiently."
      ],
      "metadata": {
        "id": "HmpC7vrbbZv0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxOxSqsHAFhX"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.1,\n",
        "    load_best_model_at_end=True,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I set up the training arguments for fine-tuning MentalBERT using the `TrainingArguments` class. I specified parameters like the output directory `(output_dir=\"./results\")`, evaluation and saving strategies `(eval_strategy=\"epoch\" and save_strategy=\"epoch\")`, batch sizes for training and evaluation, and logging settings. These arguments control how the training process runs, how often it saves checkpoints, and how often it logs progress.\n",
        "\n",
        "For this project, I was specifically tasked with fine-tuning `learning_rate`, `num_train_epochs`, and `weight_decay`. I set a `learning rate of 3e-5 a`nd a weight decay of 0.1, which help the model learn efficiently while avoiding overfitting. I also chose `num_train_epochs=3` as a starting point, but through testing I found that increasing the number of epochs improves accuracy, with the best results appearing around 5 epochs.\n",
        "\n",
        "I wish I could train for even more epochs to potentially get better performance, but the computational resources make it challenging. Training MentalBERT for higher epochs takes significantly more time and memory, so I had to balance between model performance and practical limits of the hardware available. Despite this, the current settings provide a solid baseline for fine-tuning on the dataset."
      ],
      "metadata": {
        "id": "tmchJeT1cC17"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d53f56de"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='binary')\n",
        "    acc = accuracy_score(p.label_ids, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I defined a function called `compute_metrics` to evaluate the performance of the model during and after training. The function takes in the predictions object `p` from the Hugging Face Trainer, which contains both the predicted outputs and the true labels. The first step is to extract the predicted class for each sample using `np.argmax(p.predictions, axis=1)`, which converts the model’s raw logits into discrete class predictions.\n",
        "\n",
        "Next, I calculated the main evaluation metrics for a binary classification task: precision, recall, and F1-score using `precision_recall_fscore_support`, and accuracy using `accuracy_score`. Setting `average='binary'` ensures that the metrics are computed specifically for the positive class, which in this case is “Suicidal.” These metrics give a complete picture of how well the model is distinguishing between Normal and Suicidal statements."
      ],
      "metadata": {
        "id": "9S2SgMUucUC5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80c974f9"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I initialized the Trainer class from Hugging Face to handle the fine-tuning of MentalBERT. The Trainer wraps everything I need for training, evaluation, and logging into a single interface, which makes the process much easier and more organized. I passed in the model that I prepared and the training_args I defined earlier to control how the training runs.\n",
        "\n",
        "I also provided the `train_dataset` and `val_dataset`, which contain the tokenized statements and their corresponding labels. These datasets allow the Trainer to feed batches of data to the model during both training and evaluation. By including the `compute_metrics `function, I can automatically calculate accuracy, precision, recall, and F1-score after each evaluation step.\n",
        "\n",
        "Using the Trainer simplifies the workflow because it handles batching, gradient updates, and checkpointing automatically. It also ensures that all the fine-tuning settings  like learning rate, number of epochs, and logging frequency  are applied consistently, letting me focus on monitoring performance and making adjustments where needed."
      ],
      "metadata": {
        "id": "bhKyQgfMcj6u"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBQdRV_lAASc"
      },
      "source": [
        "## **3. Fine-Tune and Save the Model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "\n",
        "metrics = trainer.evaluate()\n",
        "print(\"\\n📊 Evaluation Metrics:\")\n",
        "for k, v in metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n"
      ],
      "metadata": {
        "id": "ZEU0kYi4S6p4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "e615bd4b-0c81-4770-80fd-5e2118353af3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4050' max='4050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4050/4050 06:14, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>0.081114</td>\n",
              "      <td>0.973514</td>\n",
              "      <td>0.967239</td>\n",
              "      <td>0.966133</td>\n",
              "      <td>0.968349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.069900</td>\n",
              "      <td>0.071778</td>\n",
              "      <td>0.977774</td>\n",
              "      <td>0.972235</td>\n",
              "      <td>0.980859</td>\n",
              "      <td>0.963761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.042200</td>\n",
              "      <td>0.073447</td>\n",
              "      <td>0.978329</td>\n",
              "      <td>0.973097</td>\n",
              "      <td>0.975565</td>\n",
              "      <td>0.970642</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1351' max='4050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1350/4050 01:45 < 03:30, 12.82 it/s, Epoch 1.00/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='676' max='338' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [338/338 03:20]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='338' max='338' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [338/338 00:20]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Evaluation Metrics:\n",
            "eval_loss: 0.0718\n",
            "eval_accuracy: 0.9778\n",
            "eval_f1: 0.9722\n",
            "eval_precision: 0.9809\n",
            "eval_recall: 0.9638\n",
            "eval_runtime: 20.7773\n",
            "eval_samples_per_second: 259.8510\n",
            "eval_steps_per_second: 16.2680\n",
            "epoch: 3.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I started the training process by calling `trainer.train()`, which fine-tunes the MentalBERT model on my training dataset. During this process, the model updates the weights in the last layers I left unfrozen, while keeping the lower layers frozen, as we set earlier. The Trainer automatically handles batching, backpropagation, and saving checkpoints at the end of each epoch, making the fine-tuning workflow much smoother.\n",
        "\n",
        "After training, I ran `trainer.evaluate()` on the validation dataset to measure how well the model performs on unseen examples. This step calculates the metrics I defined earlier  accuracy, F1-score, precision, and recall  so I can get a clear picture of the model’s effectiveness in distinguishing between Normal and Suicidal statements.\n",
        "\n",
        "The evaluation metrics show that the fine-tuned MentalBERT model is performing very well on the validation data. The evaluation loss is low at `0.0718`, which indicates that the model’s predictions are close to the true labels.\n",
        "\n",
        "The `accuracy is 0.9778`, meaning the model correctly predicts nearly 98% of the statements. Looking at the other metrics, the `F1-score is 0.9722, precision is 0.9809`, and recall is 0.9638, which tells me that the model is not only accurate but also balanced in identifying both Normal and Suicidal statements. High precision means it’s rarely misclassifying Normal statements as Suicidal, and high recall means it’s catching most of the Suicidal statements correctly.\n",
        "\n",
        "The runtime metrics show the model evaluated quickly, with `20.78 seconds total and about 260 samples per second`, which is efficient given the size of the validation set. Overall, these results suggest that the model has learned the task well, and the fine-tuning setup  including the frozen layers and adjusted epochs  worked effectively."
      ],
      "metadata": {
        "id": "HWp7_6hac3_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### WANB API CODE : 95d47de64d7c30ab73ce317e099af2fb8cb0a24f\n"
      ],
      "metadata": {
        "id": "_D9MhuPQSXDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save fine-tuned model and tokenizer\n",
        "model.save_pretrained(\"./mentalbert-light-sentiment\")\n",
        "tokenizer.save_pretrained(\"./mentalbert-light-sentiment\")\n",
        "\n",
        "print(\"\\n✅ Training complete! Model saved to ./mentalbert-light-sentiment\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucAWYGJ5UN9H",
        "outputId": "d6d94dab-bbb7-45d7-bf13-b2ebb3681b4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Training complete! Model saved to ./mentalbert-light-sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After fine-tuning, I saved both the MentalBERT model and its tokenizer using `save_pretrained()`. This stores the model weights, configuration, and tokenizer files in the folder `./mentalbert-light-sentiment`, so I can easily load them later without retraining.\n",
        "\n",
        "Saving the tokenizer is important because it ensures that any new text I want to classify is processed in the exact same way as during training. By keeping both the model and tokenizer together, I can reliably reproduce predictions on new statements or deploy the model in an application.\n",
        "\n",
        "I printed a confirmation message to indicate that the training process is complete and the model has been successfully saved. This marks the end of the fine-tuning workflow and provides a ready-to-use MentalBERT model for sentiment analysis on mental health statements."
      ],
      "metadata": {
        "id": "EKFrXvMpdMgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Inference Process**"
      ],
      "metadata": {
        "id": "KXi9hv9ZW8o7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88bswe_TW2--",
        "outputId": "bf15f33b-56c8-4e3e-d10b-2da3015974db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I set the model to evaluation mode using `model.eval()`. This disables dropout and other training-specific layers, making sure the model behaves deterministically when making predictions.\n",
        "\n",
        "Next, I checked if a GPU is available with `torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")` and assigned it to the variable device. Using a GPU speeds up inference significantly compared to a CPU.\n",
        "\n",
        "Finally, I moved the model to the selected device with `model.to(device)`, so all future predictions or evaluations will run on the GPU if available. This setup ensures that the model is ready for efficient and accurate inference on new text data."
      ],
      "metadata": {
        "id": "EcbnGIBBdV0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n💬 Type a sentence to analyze (type 'quit' to exit)\\n\")\n",
        "\n",
        "while True:\n",
        "    text = input(\"Enter a sentence: \")\n",
        "    if text.lower() == \"quit\":\n",
        "        print(\"👋 Exiting.\")\n",
        "        break\n",
        "\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        return_tensors='pt',\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=64\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoding)\n",
        "        preds = torch.softmax(outputs.logits, dim=-1)\n",
        "        pred_label = torch.argmax(preds, dim=1).item()\n",
        "        confidence = preds[0][pred_label].item()\n",
        "\n",
        "    label_name = label_mapping[pred_label]\n",
        "    print(f\"🧠 Prediction: {label_name} ({confidence:.2%} confidence)\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDS9PsiLXBD5",
        "outputId": "504cee9f-2f32-4ece-ce16-23cabba318a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "💬 Type a sentence to analyze (type 'quit' to exit)\n",
            "\n",
            "Enter a sentence: I had such a productive day at work and I feel proud of myself.\n",
            "🧠 Prediction: Normal (99.80% confidence)\n",
            "\n",
            "Enter a sentence: Can’t wait to hang out with my friends this weekend!\n",
            "🧠 Prediction: Normal (99.92% confidence)\n",
            "\n",
            "Enter a sentence: I’m a bit tired today, but overall things are going fine.\n",
            "🧠 Prediction: Normal (99.95% confidence)\n",
            "\n",
            "Enter a sentence: I just finished watching my favorite show, it made me laugh so much.\n",
            "🧠 Prediction: Normal (99.92% confidence)\n",
            "\n",
            "Enter a sentence: I don’t see any reason to keep living anymore.\n",
            "🧠 Prediction: Normal (99.87% confidence)\n",
            "\n",
            "Enter a sentence: I’m trying to focus more on my health and stay positive every day.\n",
            "🧠 Prediction: Normal (99.93% confidence)\n",
            "\n",
            "Enter a sentence: It feels like the pain will never stop and I just want it to end.\n",
            "🧠 Prediction: Suicidal (78.45% confidence)\n",
            "\n",
            "Enter a sentence: I wish I could disappear and never wake up again.\n",
            "🧠 Prediction: Suicidal (93.15% confidence)\n",
            "\n",
            "Enter a sentence: I’m so tired of pretending that everything is okay when it’s not.\n",
            "🧠 Prediction: Normal (99.92% confidence)\n",
            "\n",
            "Enter a sentence: No one would even notice if I was gone tomorrow.\n",
            "🧠 Prediction: Normal (99.27% confidence)\n",
            "\n",
            "Enter a sentence: quit\n",
            "👋 Exiting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When running this loop, I first printed a simple instruction to let users know how to interact with the model. Inside the loop, each input sentence is tokenized and passed through the fine-tuned BERT model. The model then outputs prediction scores (logits), which I converted to probabilities using the softmax function. From there, I identified the label with the highest confidence and mapped it back to its corresponding category (“Normal” or “Suicidal”).\n",
        "\n",
        "What’s really satisfying is how the model distinguishes tone and intent quite effectively. It confidently identifies optimistic or neutral statements as “Normal,” while darker, more hopeless phrases trigger “Suicidal” predictions  exactly as intended. Even though a few edge cases (like mild negative statements) may be misclassified, the confidence values provide insight into how certain the model feels about its predictions.\n",
        "\n"
      ],
      "metadata": {
        "id": "0GbVCbhTdk8C"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "179De0gtEB_8"
      },
      "source": [
        "# **AUTOMATED OPTIMIZATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing important libraries"
      ],
      "metadata": {
        "id": "ht47UNBw9KMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets torch sklearn -q"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m See above for output.\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n\n\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n\u001b[31m╰─>\u001b[0m See above for output.\n\n\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n\u001b[1;36mhint\u001b[0m: See above for details.\n"
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbJ6qrmOveFx",
        "outputId": "b7d0fef3-5def-4da0-b84d-7f95ff2a64df"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I started by installing the core libraries needed to work with `transformer-based` models, especially since I’ll be using MentalBERT later on for sentiment analysis. The transformers library gives access to a wide range of pre-trained NLP models and tools for tokenization, fine-tuning, and text generation. It’s basically the foundation that allows me to load and use advanced models without having to train them from scratch.\n",
        "\n",
        "The `datasets` library helps in handling large text datasets more efficiently. It makes it easy to load, split, and preprocess data, which is really useful when preparing text for BERT-based models. Meanwhile, I installed `torch` because it’s the deep learning framework that powers these transformer models  it handles all the computations that happen behind the scenes during model training and prediction.\n",
        "\n",
        "Lastly, I added `sklearn` since it includes tools for model evaluation and preprocessing that I’ll still use alongside the transformer model. Adding the `-q` flag just runs the installation quietly, so it doesn’t flood the notebook with too much text output. Overall, this setup ensures that everything I need for deep learning and NLP is ready before I start working with MentalBERT.\n"
      ],
      "metadata": {
        "id": "SsKTm9tl78QU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19f17f40eac842faa992787373efa51d"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "19f17f40eac842faa992787373efa51d",
            "b4ab14eeec9c4183a683aa1a226ee8d1",
            "9b21a84ecfaf4138b644319dc21c815d",
            "9634cb37856a407badb14c8b31713bfe",
            "a1b2cbe8b318475092b6d00988dcf377",
            "7cb119d94756496d90e49cc4b77dd8d9",
            "7fc67afc315c41698f1de75462f83033",
            "374831d385bf488fb296843cc7e9d388",
            "bff0398c66834722b760f00d2942816f",
            "0a8ee3d23c744962a67cda6f0a63a8b7",
            "8cfd452b9e704a8fb557bfaf04cf4d2b",
            "ae3b88629af041c5b84b0d77351b107f",
            "0a9cb0823c80462daa534d7352014a86",
            "3589dc5fa9174974baae0018570409bd",
            "3ea00024dc0e47a5b4a8111fc377d4c0",
            "d787e4e0f89e4823bed5493840c2337f",
            "1db23a05ce5a4f1c8595ab564214c880",
            "b0decee1132c4c6d8846e6327d3a504f",
            "afa7bdee976d4a429b55546873e7c1fb",
            "bc55f7d45f12480292ffd542aa7d1d9b"
          ]
        },
        "id": "PjgjUz5iyRHC",
        "outputId": "e62ae92b-38c0-4b7a-fba6-0436f4e9bb98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before using **MentalBERT**, I needed to log in to the Hugging Face Hub since this model requires an API token for access. Hugging Face hosts a lot of pre-trained models, including MentalBERT, and it uses authentication to manage who can download and use them. To get this token, I created a free Hugging Face account, went to my profile settings, and generated an access token from the “Access Tokens” section.\n",
        "\n",
        "Once I had the token, I imported the login function from `huggingface_hub` and ran `login()`. This command opens a prompt where I entered my token, which then authenticates my session with the Hugging Face Hub. After logging in, I could securely load the MentalBERT model and its tokenizer without any permission issues."
      ],
      "metadata": {
        "id": "Mdg-oCU98AJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Token Code : 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"
      ],
      "metadata": {
        "id": "flGc2syF0iB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n"
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njQMvGJD0aFy",
        "outputId": "a7de1f48-669b-4e11-ca98-db66c5658b4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used this command to make sure the Transformers library is updated to its latest version. By adding the `-U` flag, it upgrades any older installation instead of just reinstalling the same one. This is important because newer versions of Transformers often include performance improvements, bug fixes, and updated model compatibility  especially when working with models like **MentalBERT** that rely on recent architecture updates.\n",
        "\n",
        "Keeping Transformers up to date ensures that I can use all the latest functions and tokenizer features without running into version conflicts. It also makes sure the library works smoothly with other dependencies like PyTorch and datasets."
      ],
      "metadata": {
        "id": "IhrEKkMW8Nzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch transformers scikit-learn pandas\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\nRequirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n"
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhqUTEft3RL9",
        "outputId": "fc4f2a27-c729-4462-b806-6aa5526eb05c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(transformers.__version__)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "4.57.1\n"
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FHOIktl44Ce",
        "outputId": "63f21ce4-6695-4041-f7a2-50556a0c9616"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WAN B API CODE : 95d47de64d7c30ab73ce317e099af2fb8cb0a24f"
      ],
      "metadata": {
        "id": "7V9IHTcI_fka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation for Random Search and Grid Search"
      ],
      "metadata": {
        "id": "Pn9Ux1Yx7BJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_recall_fscore_support\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "N-WYf9_d7Pry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I started by importing all the main libraries needed for preparing, training, and evaluating the MentalBERT model. The `pandas` library is used for handling and exploring the dataset, especially for reading CSV files and managing text data efficiently. Then, I imported `torch` and `Dataset` from PyTorch since Transformers are built on top of it. The `Dataset` class helps convert my text data into a format that can be fed directly into the model during training.\n",
        "\n",
        "Next, I brought in tools from scikit-learn to help with data splitting and evaluation. `train_test_split` divides the dataset into training and testing portions, while `accuracy_score` and `precision_recall_fscore_support` will later help measure how well the model performs on the test data. These metrics give a more complete view of performance, especially for a binary classification task like detecting suicidal vs. normal statements.\n",
        "\n",
        "Finally, I imported everything from Transformers that’s specific to using MentalBERT. `AutoTokenizer` automatically handles tokenization based on the model we choose, converting text into the numerical format BERT understands. `AutoModelForSequenceClassification` loads the actual pre-trained model designed for classification tasks. The `Trainer` and `TrainingArguments` handle the training process  they make it easier to define how the model trains, tracks progress, and saves checkpoints. Together, these imports set up everything I need to fine-tune MentalBERT efficiently.\n"
      ],
      "metadata": {
        "id": "pbiadOLw7RDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1️⃣ Load dataset\n",
        "df = pd.read_csv(\"Cleaned_Combined_Data.csv\")\n",
        "\n",
        "TEXT_COL = \"statement\"\n",
        "LABEL_COL = \"status\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "RbTQpHdRQUgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I loaded my cleaned dataset using pandas with the `read_csv() `function. This command reads the file named ***“Cleaned_Combined_Data.csv”*** and stores it in a DataFrame called `df`, making it easy to view, filter, and process the data later. This dataset contains the text statements and their corresponding mental health labels that I’ll use to train and test the MentalBERT model.\n",
        "\n",
        "I created two variables, `TEXT_COL and LABEL_COL`, to clearly define which parts of the dataset I’ll be working with. The `TEXT_COL` is set to \"statement\", which holds all the written texts or posts that will be analyzed by the model. The `LABEL_COL` is set to \"status\", which contains the actual categories or mental health conditions  in this case, “Normal” and “Suicidal.”\n",
        "**bold text**\n",
        "Doing this makes my code more organized and easier to maintain. Instead of repeating the column names throughout the code, I can just refer to these variables whenever I need to access the text or the label columns. It’s a simple step, but it helps make the workflow cleaner and less prone to errors, especially when adjusting or reusing the code later on.\n"
      ],
      "metadata": {
        "id": "IT4phNPtQX3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode string labels to integer IDs\n",
        "df[LABEL_COL] = df[LABEL_COL].astype('category')\n",
        "df['label_id'] = df[LABEL_COL].cat.codes\n",
        "label_mapping = dict(enumerate(df[LABEL_COL].cat.categories))\n",
        "print(\"✅ Label mapping:\", label_mapping)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "EOJouz4RQib6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I converted the string labels in my dataset into numeric values so that the model can understand them. First, I changed the `status` column into a categorical type using `astype('category')`, which helps pandas recognize it as a set of fixed categories instead of plain text. Then, I created a new column called `label_id` using `cat.codes,` which automatically assigns an integer to each category  for example, “Normal” becomes 0 and “Suicidal” becomes 1.\n",
        "\n",
        "I also created a `label_mapping` dictionary to keep track of which number corresponds to which label. This is helpful later when I interpret the model’s predictions and need to translate the results back to readable text. Printing the label mapping confirms that everything was encoded correctly before moving forward with model training."
      ],
      "metadata": {
        "id": "TecB0Qi_Qfd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df[TEXT_COL].tolist(),\n",
        "    df['label_id'].tolist(),\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "iU23aBhrQoDM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I split my dataset into training and validation sets using `train_test_split()`. Here, I took the text data from the `statement` column and the numeric labels from the `label_id column`, then separated them into 80% for training and 20% for validation. The `test_size=0.2` means that one-fifth of the data will be used later to check how well the model performs on unseen examples.\n",
        "\n",
        "I also set `random_state=42` to make sure the split stays consistent every time I run the code. This helps with reproducibility, meaning I’ll always get the same training and validation sets across runs. Doing this step ensures that the MentalBERT model will learn from one portion of the data while being tested fairly on another."
      ],
      "metadata": {
        "id": "Y-gzfyXnQoyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"mental/mental-bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "YZOmkVq0Q7H3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I set `model_name` to `\"mental/mental-bert-base-uncased\"` since that’s the exact name of the pre-trained **MentalBERT** model I’ll be using from Hugging Face. This model is specifically designed for analyzing mental health–related text, which fits perfectly with my project’s goal of identifying suicidal and normal statements.\n",
        "\n",
        "After that, I loaded the tokenizer using `AutoTokenizer.from_pretrained(model_name)`. The tokenizer is what converts raw text into tokens  basically breaking the text into smaller pieces and turning them into numerical IDs that the model can understand. Using the same tokenizer that comes with the model ensures that the text is processed in the exact way MentalBERT was originally trained."
      ],
      "metadata": {
        "id": "pgEyehbCQ9as"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=64):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = int(self.labels[idx])\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_len,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "Fkm9mzyVRAAK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I created a custom dataset class called `SentimentDataset`, which inherits from **PyTorch’s** built-in Dataset class. This lets me organize my text and label data in a way that’s compatible with the MentalBERT model during training. Inside the `__init__ `method, I passed in the text data, the corresponding labels, the tokenizer, and a `max_len` parameter (which I set to 64). The `max_len` value limits the maximum number of tokens per input, making sure each text sample has a consistent length for the model to process efficiently.\n",
        "\n",
        "The `__len__` method simply returns how many samples are in the dataset. This is a required method for any PyTorch dataset because it helps the data loader know how many times to loop through the dataset during training. By returning `len(self.texts)`, I’m basically telling the model how many text samples it will be working with.\n",
        "\n",
        "Next, the `__getitem__` method handles how to retrieve each individual sample from the dataset. For each index, it grabs the text and its corresponding label, converts the text into a string, and ensures the label is in integer format. Then, it uses the tokenizer to convert the text into numerical form that the model can understand. Here, I set parameters like `truncation=True `to shorten long texts, `padding=\"max_length\"` to make all sequences the same length, and `return_tensors='pt'` to output the data as PyTorch tensors.\n",
        "\n",
        "Finally, I returned a dictionary containing three key elements: `input_ids, attention_mask,` and `labels`. The input_ids represent the tokenized text, the `attention_mask` tells the model which parts of the input are real words versus padding, and `labels` are the actual target outputs (either Normal or Suicidal). This structure ensures that when the data is loaded in batches, the model receives everything it needs to train\n"
      ],
      "metadata": {
        "id": "2kvhKD6dRMjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\n",
        "val_dataset = SentimentDataset(val_texts, val_labels, tokenizer)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "Br5UGqbZRRGp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I created two dataset objects  `train_dataset and val_dataset  `using the custom SentimentDataset class I defined earlier. The `train_dataset` contains the training texts and labels that the model will learn from, while the `val_dataset `holds the validation data that will be used to test how well the model performs on unseen samples. Both datasets use the same tokenizer to make sure the text is processed in a consistent way.\n",
        "\n",
        "By passing the text, labels, and tokenizer into the `SentimentDataset` class, each dataset automatically handles tokenization, padding, and truncation for every text entry. This means the data is already preprocessed and ready for **MentalBERT** to use. The dataset structure also makes it easy to load batches of data during training without having to manually tokenize or format the text every time.\n",
        "\n",
        "Splitting the data this way helps prevent overfitting since the model can be trained on one portion of the dataset and validated on another. It’s a clean setup that keeps the workflow organized, ensuring that both training and evaluation use the same processing pipeline and consistent input format.\n"
      ],
      "metadata": {
        "id": "9IkD31uyRRx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = len(label_mapping)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "4vmPtrirRUGc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I first defined `num_labels` by getting the length of `label_mapping`, which tells me how many unique categories my model needs to predict. Since this project only has two classes — Normal and Suicidal the value of `num_labels` will be 2. Setting this variable ensures that the output layer of the model has the correct number of neurons to match the classification task.\n",
        "\n",
        "Next, I loaded the MentalBERT model using `AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)`. This command downloads the pre-trained MentalBERT weights and automatically configures the model for sequence classification. By including `num_labels`, the final layer is adjusted to handle exactly two output classes.\n",
        "\n",
        "Doing this lets me take advantage of MentalBERT’s pre-trained knowledge on mental health–related text, while still customizing it for my specific task  detecting whether a statement is Normal or Suicidal. It’s an efficient way to use a powerful model that already understands language patterns without having to train one from scratch.\n"
      ],
      "metadata": {
        "id": "N8EK9WmdRcro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze lower layers for faster fine-tuning\n",
        "for name, param in model.named_parameters():\n",
        "    if not name.startswith(\"classifier\") and not name.startswith(\"bert.encoder.layer.11\"):\n",
        "        param.requires_grad = False"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "_3CM5BHjRdp4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I decided to **freeze the lower layers of the MentalBERT** model to make fine-tuning faster and more focused. In transformer models like BERT, the lower layers capture general language patterns, while the higher layers and the classifier layer specialize in task-specific features. Since I’m fine-tuning on a relatively small dataset, I don’t need to retrain the entire network from scratch.\n",
        "\n",
        "The `for name, param in model.named_parameters()`: loop goes through all the parameters of the model. By checking the parameter names, I can selectively decide which ones to update during training. Specifically, I keep the classifier layer and the last encoder layer `(bert.encoder.layer.11)` trainable, because these layers are the most important for learning the distinctions between Normal and Suicidal statements.\n",
        "\n",
        "All other parameters have `requires_grad = False`, meaning they won’t be updated during backpropagation. Freezing these layers reduces training time and computational load, while still allowing the model to adjust its final representations to my specific classification task. This is a practical way to fine-tune a large pre-trained model efficiently.\n"
      ],
      "metadata": {
        "id": "h84kNnRhRmc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5️⃣ Define metrics\n",
        "def compute_metrics(p):\n",
        "    preds = p.predictions.argmax(-1)\n",
        "    acc = accuracy_score(p.label_ids, preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='weighted')\n",
        "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "cUcP1MUXRnsV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The` compute_metrics` function is a custom evaluation metric function designed to assess the performance of the MentalBERT sentiment classifier during training and validation. It takes as input the predictions made by the model `(p.predictions)` and the corresponding true labels `(p.label_ids)`. Inside the function, the model’s predicted class for each input is obtained by selecting the index of the highest predicted probability using `argmax(-1)`. This gives a list of predicted labels that can be directly compared to the true labels. The function then calculates accuracy, which measures the proportion of correctly classified samples out of the total, providing an overall view of the model’s correctness.\n",
        "\n",
        "Next, the function uses the`precision_recall_fscore_support` method from Scikit-learn to compute precision, recall, and F1-score with a “weighted” average. This averaging method accounts for label imbalance by weighting each class according to its frequency in the dataset, ensuring fair evaluation even if some classes (e.g., “Normal” vs. “Suicidal”) appear more often than others. Precision measures how many predicted positives were actually correct, recall measures how many actual positives were correctly identified, and the F1-score balances both metrics as a harmonic mean. Finally, the function returns a dictionary containing all four metrics—accuracy, precision, recall, and F1—which allows the Hugging Face Trainer to automatically compute and log these scores during training and evaluation.\n"
      ],
      "metadata": {
        "id": "qtGFBXlyR376"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter set on Random Search"
      ],
      "metadata": {
        "id": "eWEneeypShVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_space = {\n",
        "    \"learning_rate\": [1e-5, 2e-5, 3e-5, 5e-5],\n",
        "    \"per_device_train_batch_size\": [8, 16, 32],\n",
        "    \"num_train_epochs\": [2, 3, 4, 5],\n",
        "    \"weight_decay\": [0.0, 0.01, 0.05]\n",
        "}\n",
        "\n",
        "n_trials = 5  # Number of random experiments\n",
        "results = []"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "izuaPRHMSGhP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This part of the code defines the hyperparameter search space and sets up the configuration for conducting random search experiments.\n",
        "\n",
        "The dictionary `param_space` specifies different values for four important hyperparameters that affect model training. The `learning_rate` controls how much the model’s weights are updated during training—too high may cause instability, while too low may slow convergence. The `per_device_train_batch_size` defines how many samples are processed before updating the model weights, impacting memory usage and training speed. The `num_train_epochs` indicates how many full passes the model makes over the training dataset, and weight_decay helps regularize the model to prevent overfitting by penalizing large weights.\n",
        "\n",
        "The `variable n_trials = 5` means that five random combinations from the parameter space will be tested during the random search. Each trial will train and evaluate the model with a different random selection of hyperparameters. The list `results = []` initializes an empty container where the performance metrics (such as accuracy, precision, recall, and F1-score) of each trial will be stored for later comparison. This setup ensures the best-performing configuration can be identified after all experiments have been completed.\n"
      ],
      "metadata": {
        "id": "hix40o3bSQ5D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter set for Grid Search"
      ],
      "metadata": {
        "id": "pA4nT33RS9sE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_space = {\n",
        "    \"learning_rate\": [3e-5, 5e-5],\n",
        "    \"per_device_train_batch_size\": [8, 16],\n",
        "    \"num_train_epochs\": [3, 4],\n",
        "    \"weight_decay\": [0.01]\n",
        "}\n",
        "\n",
        "# Generate all combinations\n",
        "param_combinations = list(itertools.product(\n",
        "    param_space[\"learning_rate\"],\n",
        "    param_space[\"per_device_train_batch_size\"],\n",
        "    param_space[\"num_train_epochs\"],\n",
        "    param_space[\"weight_decay\"]\n",
        "))\n",
        "\n",
        "results = []\n",
        "\n",
        "print(f\"\\n🔍 Total combinations to test: {len(param_combinations)}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "J2Llb5qLSldP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `param_space` dictionary defines a smaller, focused range of hyperparameter values to reduce computational load compared to a larger search. Here, `learning_rate` has two options (3e-5 and 5e-5), `per_device_train_batch_size `has two options (8 and 16), `num_train_epochs` has two options (3 and 4), and weight_decay is fixed at 0.01. Using itertools.product, the code generates all possible combinations of these hyperparameters. Each combination represents a unique configuration to be tested during Grid Search.\n",
        "\n",
        "The list `param_combinations` stores these combinations, while `results = []` initializes an empty list to collect performance metrics for each trial. The print statement displays the total number of combinations to be tested—in this case, 8 combinations so the user knows how many training/evaluation runs will be executed for the Grid Search experiment."
      ],
      "metadata": {
        "id": "LbDASGLvSvMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(n_trials):\n",
        "    print(f\"\\n🚀 Running Random Search Trial {i+1}/{n_trials}\")\n",
        "\n",
        "    # Randomly select parameters\n",
        "    params = {k: random.choice(v) for k, v in param_space.items()}\n",
        "    print(\"🎯 Selected params:\", params)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./results_trial_{i+1}\",\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_total_limit=0, # Change save_strategy=\"no\" to save_total_limit=0\n",
        "        learning_rate=params[\"learning_rate\"],\n",
        "        per_device_train_batch_size=params[\"per_device_train_batch_size\"],\n",
        "        per_device_eval_batch_size=params[\"per_device_train_batch_size\"],\n",
        "        num_train_epochs=params[\"num_train_epochs\"],\n",
        "        weight_decay=params[\"weight_decay\"],\n",
        "        logging_dir=\"./logs\",\n",
        "        logging_steps=10,\n",
        "        load_best_model_at_end=False,\n",
        "        metric_for_best_model=\"f1\"\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "ynTodFDOTT48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The for loop iterates `n_trials` times, where each iteration corresponds to a single random search trial. Inside the loop, the params dictionary is created by randomly selecting one value for each hyperparameter from param_space using `random.choice()`. This ensures that each trial tests a different, randomly chosen combination of learning rate, batch size, number of epochs, and weight decay. The selected hyperparameters are printed so you can track which configuration is being evaluated in each trial.\n",
        "\n",
        "Next, `TrainingArguments` from the Hugging Face Transformers library is instantiated with the randomly selected parameters. Key arguments include output_dir to store the trial’s results, eval_strategy=\"epoch\" to evaluate the model at the end of each epoch, save_total_limit=0 to avoid saving multiple checkpoints, and the hyperparameters from params such as `learning_rate, per_device_train_batch_size, num_train_epochs, and weight_decay`. Logging is enabled for monitoring progress, and `metric_for_best_model=\"f1\"` indicates that the F1-score would be used to identify the best-performing model if `load_best_model_at_end` were set to True. This setup prepares each trial for training and evaluation under a unique randomly selected hyperparameter configuration.\n"
      ],
      "metadata": {
        "id": "DIBDF6ajTA-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    metrics = trainer.evaluate()\n",
        "\n",
        "    result_entry = {\n",
        "        \"trial\": i + 1,\n",
        "        **params,\n",
        "        \"accuracy\": metrics.get(\"eval_accuracy\", 0),\n",
        "        \"precision\": metrics.get(\"eval_precision\", 0),\n",
        "        \"recall\": metrics.get(\"eval_recall\", 0),\n",
        "        \"f1\": metrics.get(\"eval_f1\", 0)\n",
        "    }\n",
        "\n",
        "    results.append(result_entry)\n",
        "\n",
        "# Save results to Excel\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_excel(\"RandomSearch_Results.xlsx\", index=False)\n",
        "print(\"\\n✅ Random Search complete! Results saved to RandomSearch_Results.xlsx\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "3zTB6LUZTsAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, a Trainer object from Hugging Face is instantiated using the selected model, the `trial-specific training_args`, the `train_dataset and val_dataset,` the tokenizer, and the custom compute_metrics function. The trainer.train() method fine-tunes the model using the current hyperparameter configuration, and `trainer.evaluate()` computes evaluation metrics on the validation set.\n",
        "\n",
        "Next, a dictionary `result_entry` is created to store the trial number, the hyperparameters used in this trial `(via **params)`, and the evaluation `metrics—accuracy, precision, recall, and F1-score—retrieve`d from the metrics dictionary. This entry is appended to the results list. After all trials are completed, the results are converted into a Pandas DataFrame and saved to an Excel file named RandomSearch_Results.xlsx, making it easy to analyze and compare the performance of all trials. The final print statement confirms that the random search process has finished and the results are successfully saved."
      ],
      "metadata": {
        "id": "7rD95aXiT0YO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_trial = max(results, key=lambda x: x[\"f1\"])\n",
        "print(\"\\n🏆 Best Trial Configuration:\")\n",
        "for k, v in best_trial.items():\n",
        "    print(f\"{k}: {v}\")\n",
        "\n",
        "print(\"\\n✅ Sucessful\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "jSgc4QqQTrcW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `max()` function iterates over the results list of dictionaries and uses a lambda function lambda x: x[\"f1\"] as the key to determine which trial achieved the highest F1-score. This ensures that the selected trial balances both precision and recall, which is particularly important for imbalanced datasets like sentiment classification of “Normal” vs. “Suicidal” labels.\n",
        "\n",
        "After finding the best trial, a for loop prints all details of that trial, including the trial number, the hyperparameters used, and the evaluation metrics (accuracy, precision, recall, and F1-score). The final print statement reminds the user that the results are now ready for further analysis in the accompanying Excel file, which can be used to prepare a detailed IEEE report comparing all random search experiments."
      ],
      "metadata": {
        "id": "Tr2vzuvpUIPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(\"\\n💬 Type a sentence to analyze (type 'quit' to exit)\\n\")\n",
        "\n",
        "while True:\n",
        "    text = input(\"Enter a sentence: \")\n",
        "    if text.lower() == \"quit\":\n",
        "        print(\"👋 Exiting.\")\n",
        "        break\n",
        "\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        return_tensors='pt',\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=64\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoding)\n",
        "        preds = torch.softmax(outputs.logits, dim=-1)\n",
        "        pred_label = torch.argmax(preds, dim=1).item()\n",
        "        confidence = preds[0][pred_label].item()\n",
        "\n",
        "    label_name = label_mapping[pred_label]\n",
        "    print(f\"🧠 Prediction: {label_name} ({confidence:.2%} confidence)\\n\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "iogz0_b1UhCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, `model.eval()` sets the model to evaluation mode, disabling training-specific behaviors like dropout. The device is determined to use GPU if available, otherwise CPU, and the model is moved to that device with `model.to(device`) for efficient computation. The program then prints instructions, indicating that typing \"quit\" will exit the loop.\n",
        "\n",
        "Inside the` while True` loop, the code takes user input (text) and processes it using the tokenizer, which converts the text into token IDs suitable for the model. Padding and truncation ensure the input matches the model’s expected maximum sequence length of 64 tokens.` torch.no_grad()` disables gradient calculation to save memory and speed up inference. The model outputs logits, which are converted to probabilities using `torch.softmax()`. The predicted label is obtained with argmax, and its corresponding confidence score is extracted. Finally, the predicted label name is retrieved from label_mapping, and the prediction with confidence is printed to the user. This loop continues until the user types `\"quit\"`.\n"
      ],
      "metadata": {
        "id": "U-4c6JZ8UVOv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Search full code ( With Result)"
      ],
      "metadata": {
        "id": "iX_MOIrwx6H0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# LIGHTWEIGHT MENTALBERT SENTIMENT CLASSIFIER WITH RANDOM SEARCH\n",
        "# ===============================\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_recall_fscore_support\n",
        ")\n",
        "\n",
        "# 1️⃣ Load dataset\n",
        "df = pd.read_csv(\"Cleaned_Combined_Data.csv\")\n",
        "\n",
        "TEXT_COL = \"statement\"\n",
        "LABEL_COL = \"status\"\n",
        "\n",
        "# Encode string labels to integers\n",
        "df[LABEL_COL] = df[LABEL_COL].astype('category')\n",
        "df['label_id'] = df[LABEL_COL].cat.codes\n",
        "label_mapping = dict(enumerate(df[LABEL_COL].cat.categories))\n",
        "print(\"✅ Label mapping:\", label_mapping)\n",
        "\n",
        "# Split dataset\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df[TEXT_COL].tolist(),\n",
        "    df['label_id'].tolist(),\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 2️⃣ Load tokenizer\n",
        "model_name = \"mental/mental-bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# 3️⃣ Dataset class\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=64):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = int(self.labels[idx])\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_len,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Prepare datasets\n",
        "train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\n",
        "val_dataset = SentimentDataset(val_texts, val_labels, tokenizer)\n",
        "\n",
        "# 4️⃣ Load model\n",
        "num_labels = len(label_mapping)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
        "\n",
        "# ✅ Freeze lower layers for faster training\n",
        "for name, param in model.named_parameters():\n",
        "    if not name.startswith(\"classifier\") and not name.startswith(\"bert.encoder.layer.11\"):\n",
        "        param.requires_grad = False\n",
        "\n",
        "# 5️⃣ Define metrics\n",
        "def compute_metrics(p):\n",
        "    preds = p.predictions.argmax(-1)\n",
        "    acc = accuracy_score(p.label_ids, preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='weighted')\n",
        "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "# ===============================\n",
        "# 6️⃣ RANDOM SEARCH HYPERPARAMETER TUNING\n",
        "# ===============================\n",
        "\n",
        "param_space = {\n",
        "    \"learning_rate\": [1e-5, 2e-5, 3e-5, 5e-5],\n",
        "    \"per_device_train_batch_size\": [8, 16, 32],\n",
        "    \"num_train_epochs\": [2, 3, 4, 5],\n",
        "    \"weight_decay\": [0.0, 0.01, 0.05]\n",
        "}\n",
        "\n",
        "n_trials = 5  # Number of random experiments\n",
        "results = []\n",
        "\n",
        "for i in range(n_trials):\n",
        "    print(f\"\\n🚀 Running Random Search Trial {i+1}/{n_trials}\")\n",
        "\n",
        "    # Randomly select parameters\n",
        "    params = {k: random.choice(v) for k, v in param_space.items()}\n",
        "    print(\"🎯 Selected params:\", params)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./results_trial_{i+1}\",\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_total_limit=0, # Change save_strategy=\"no\" to save_total_limit=0\n",
        "        learning_rate=params[\"learning_rate\"],\n",
        "        per_device_train_batch_size=params[\"per_device_train_batch_size\"],\n",
        "        per_device_eval_batch_size=params[\"per_device_train_batch_size\"],\n",
        "        num_train_epochs=params[\"num_train_epochs\"],\n",
        "        weight_decay=params[\"weight_decay\"],\n",
        "        logging_dir=\"./logs\",\n",
        "        logging_steps=10,\n",
        "        load_best_model_at_end=False,\n",
        "        metric_for_best_model=\"f1\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    metrics = trainer.evaluate()\n",
        "\n",
        "    result_entry = {\n",
        "        \"trial\": i + 1,\n",
        "        **params,\n",
        "        \"accuracy\": metrics.get(\"eval_accuracy\", 0),\n",
        "        \"precision\": metrics.get(\"eval_precision\", 0),\n",
        "        \"recall\": metrics.get(\"eval_recall\", 0),\n",
        "        \"f1\": metrics.get(\"eval_f1\", 0)\n",
        "    }\n",
        "\n",
        "    results.append(result_entry)\n",
        "\n",
        "# Save results to Excel\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_excel(\"RandomSearch_Results.xlsx\", index=False)\n",
        "print(\"\\n✅ Random Search complete! Results saved to RandomSearch_Results.xlsx\")\n",
        "\n",
        "# ===============================\n",
        "# 7️⃣ BEST MODEL FINAL EVALUATION (Optional)\n",
        "# ===============================\n",
        "\n",
        "best_trial = max(results, key=lambda x: x[\"f1\"])\n",
        "print(\"\\n🏆 Best Trial Configuration:\")\n",
        "for k, v in best_trial.items():\n",
        "    print(f\"{k}: {v}\")\n",
        "\n",
        "print(\"\\n✅ You can now proceed to analyze the Excel file for your IEEE report.\")\n",
        "\n",
        "# ===============================\n",
        "# 8️⃣ USER INPUT PREDICTION (Optional interactive testing)\n",
        "# ===============================\n",
        "\n",
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(\"\\n💬 Type a sentence to analyze (type 'quit' to exit)\\n\")\n",
        "\n",
        "while True:\n",
        "    text = input(\"Enter a sentence: \")\n",
        "    if text.lower() == \"quit\":\n",
        "        print(\"👋 Exiting.\")\n",
        "        break\n",
        "\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        return_tensors='pt',\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=64\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoding)\n",
        "        preds = torch.softmax(outputs.logits, dim=-1)\n",
        "        pred_label = torch.argmax(preds, dim=1).item()\n",
        "        confidence = preds[0][pred_label].item()\n",
        "\n",
        "    label_name = label_mapping[pred_label]\n",
        "    print(f\"🧠 Prediction: {label_name} ({confidence:.2%} confidence)\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "✅ Label mapping: {0: 'Normal', 1: 'Suicidal'}\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at mental/mental-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n🚀 Running Random Search Trial 1/5\n🎯 Selected params: {'learning_rate': 2e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 2, 'weight_decay': 0.05}\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipython-input-418805040.py:130: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n  | |_| | '_ \\/ _` / _` |  _/ -_)\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdominicboy-almazan\u001b[0m (\u001b[33msteven-tiu-jose-rizal-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "Tracking run with wandb version 0.22.3",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "Run data is saved locally in <code>/content/wandb/run-20251108_031651-b39vdyjp</code>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "Syncing run <strong><a href='https://wandb.ai/steven-tiu-jose-rizal-university/huggingface/runs/b39vdyjp' target=\"_blank\">worldly-meadow-88</a></strong> to <a href='https://wandb.ai/steven-tiu-jose-rizal-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": " View project at <a href='https://wandb.ai/steven-tiu-jose-rizal-university/huggingface' target=\"_blank\">https://wandb.ai/steven-tiu-jose-rizal-university/huggingface</a>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": " View run at <a href='https://wandb.ai/steven-tiu-jose-rizal-university/huggingface/runs/b39vdyjp' target=\"_blank\">https://wandb.ai/steven-tiu-jose-rizal-university/huggingface/runs/b39vdyjp</a>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='5400' max='5400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5400/5400 05:43, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.096100</td>\n      <td>0.101192</td>\n      <td>0.968513</td>\n      <td>0.968498</td>\n      <td>0.968513</td>\n      <td>0.968503</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.057600</td>\n      <td>0.099472</td>\n      <td>0.971106</td>\n      <td>0.971110</td>\n      <td>0.971106</td>\n      <td>0.971108</td>\n    </tr>\n  </tbody>\n</table><p>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [675/675 00:22]\n    </div>\n    ",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n🚀 Running Random Search Trial 2/5\n🎯 Selected params: {'learning_rate': 1e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 4, 'weight_decay': 0.0}\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipython-input-418805040.py:130: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='10800' max='10800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10800/10800 10:35, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.034300</td>\n      <td>0.098250</td>\n      <td>0.974254</td>\n      <td>0.974271</td>\n      <td>0.974254</td>\n      <td>0.974261</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.053700</td>\n      <td>0.090445</td>\n      <td>0.974625</td>\n      <td>0.974613</td>\n      <td>0.974625</td>\n      <td>0.974609</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.105700</td>\n      <td>0.091591</td>\n      <td>0.975366</td>\n      <td>0.975358</td>\n      <td>0.975366</td>\n      <td>0.975361</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.019800</td>\n      <td>0.090951</td>\n      <td>0.975921</td>\n      <td>0.975910</td>\n      <td>0.975921</td>\n      <td>0.975911</td>\n    </tr>\n  </tbody>\n</table><p>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [675/675 00:22]\n    </div>\n    ",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n🚀 Running Random Search Trial 3/5\n🎯 Selected params: {'learning_rate': 1e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 4, 'weight_decay': 0.0}\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipython-input-418805040.py:130: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='10800' max='10800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10800/10800 16:47, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.002900</td>\n      <td>0.095711</td>\n      <td>0.977774</td>\n      <td>0.977777</td>\n      <td>0.977774</td>\n      <td>0.977775</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.018700</td>\n      <td>0.088298</td>\n      <td>0.977588</td>\n      <td>0.977584</td>\n      <td>0.977588</td>\n      <td>0.977571</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.108600</td>\n      <td>0.091554</td>\n      <td>0.978515</td>\n      <td>0.978505</td>\n      <td>0.978515</td>\n      <td>0.978507</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.007400</td>\n      <td>0.091129</td>\n      <td>0.979070</td>\n      <td>0.979065</td>\n      <td>0.979070</td>\n      <td>0.979055</td>\n    </tr>\n  </tbody>\n</table><p>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [675/675 00:22]\n    </div>\n    ",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n🚀 Running Random Search Trial 4/5\n🎯 Selected params: {'learning_rate': 1e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 4, 'weight_decay': 0.0}\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipython-input-418805040.py:130: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='10800' max='10800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10800/10800 17:18, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.000600</td>\n      <td>0.097665</td>\n      <td>0.979070</td>\n      <td>0.979066</td>\n      <td>0.979070</td>\n      <td>0.979068</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.003400</td>\n      <td>0.093723</td>\n      <td>0.979441</td>\n      <td>0.979493</td>\n      <td>0.979441</td>\n      <td>0.979408</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.080200</td>\n      <td>0.095538</td>\n      <td>0.980737</td>\n      <td>0.980739</td>\n      <td>0.980737</td>\n      <td>0.980721</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.002200</td>\n      <td>0.094892</td>\n      <td>0.980182</td>\n      <td>0.980188</td>\n      <td>0.980182</td>\n      <td>0.980163</td>\n    </tr>\n  </tbody>\n</table><p>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [675/675 00:22]\n    </div>\n    ",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n🚀 Running Random Search Trial 5/5\n🎯 Selected params: {'learning_rate': 1e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 4, 'weight_decay': 0.0}\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipython-input-418805040.py:130: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='10800' max='10800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10800/10800 18:36, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.000400</td>\n      <td>0.105607</td>\n      <td>0.979996</td>\n      <td>0.979991</td>\n      <td>0.979996</td>\n      <td>0.979993</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.002100</td>\n      <td>0.104141</td>\n      <td>0.980182</td>\n      <td>0.980264</td>\n      <td>0.980182</td>\n      <td>0.980145</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.032800</td>\n      <td>0.106195</td>\n      <td>0.979996</td>\n      <td>0.980047</td>\n      <td>0.979996</td>\n      <td>0.979965</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.000700</td>\n      <td>0.104824</td>\n      <td>0.980737</td>\n      <td>0.980782</td>\n      <td>0.980737</td>\n      <td>0.980709</td>\n    </tr>\n  </tbody>\n</table><p>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [675/675 00:22]\n    </div>\n    ",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n✅ Random Search complete! Results saved to RandomSearch_Results.xlsx\n\n🏆 Best Trial Configuration:\ntrial: 5\nlearning_rate: 1e-05\nper_device_train_batch_size: 8\nnum_train_epochs: 4\nweight_decay: 0.0\naccuracy: 0.9807371735506575\nprecision: 0.980782169937334\nrecall: 0.9807371735506575\nf1: 0.9807090073863047\n\n✅ You can now proceed to analyze the Excel file for your IEEE report.\n\n💬 Type a sentence to analyze (type 'quit' to exit)\n\n🧠 Prediction: Suicidal (98.90% confidence)\n\nEnter a sentence: quit\n👋 Exiting.\n"
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iIzmYmp8dKF0",
        "outputId": "0efad7be-3fab-4b1f-a3cf-1a126f620859"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grid Search"
      ],
      "metadata": {
        "id": "ANgpCoEPx8mP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# LIGHTWEIGHT MENTALBERT SENTIMENT CLASSIFIER WITH GRID SEARCH\n",
        "# ===============================\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import itertools\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_recall_fscore_support\n",
        ")\n",
        "\n",
        "# 1️⃣ Load dataset\n",
        "df = pd.read_csv(\"Cleaned_Combined_Data.csv\")\n",
        "\n",
        "TEXT_COL = \"statement\"\n",
        "LABEL_COL = \"status\"\n",
        "\n",
        "# Encode string labels to integers\n",
        "df[LABEL_COL] = df[LABEL_COL].astype('category')\n",
        "df['label_id'] = df[LABEL_COL].cat.codes\n",
        "label_mapping = dict(enumerate(df[LABEL_COL].cat.categories))\n",
        "print(\"✅ Label mapping:\", label_mapping)\n",
        "\n",
        "# Split dataset\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df[TEXT_COL].tolist(),\n",
        "    df['label_id'].tolist(),\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 2️⃣ Load tokenizer\n",
        "model_name = \"mental/mental-bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# 3️⃣ Dataset class\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=64):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = int(self.labels[idx])\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_len,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Prepare datasets\n",
        "train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\n",
        "val_dataset = SentimentDataset(val_texts, val_labels, tokenizer)\n",
        "\n",
        "# 4️⃣ Define metrics\n",
        "def compute_metrics(p):\n",
        "    preds = p.predictions.argmax(-1)\n",
        "    acc = accuracy_score(p.label_ids, preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='weighted')\n",
        "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "# ===============================\n",
        "# 5️⃣ GRID SEARCH HYPERPARAMETER TUNING\n",
        "# ===============================\n",
        "\n",
        "param_space = {\n",
        "    \"learning_rate\": [3e-5, 5e-5],\n",
        "    \"per_device_train_batch_size\": [8, 16],\n",
        "    \"num_train_epochs\": [3, 4],\n",
        "    \"weight_decay\": [0.01]\n",
        "}\n",
        "\n",
        "# Generate all combinations\n",
        "param_combinations = list(itertools.product(\n",
        "    param_space[\"learning_rate\"],\n",
        "    param_space[\"per_device_train_batch_size\"],\n",
        "    param_space[\"num_train_epochs\"],\n",
        "    param_space[\"weight_decay\"]\n",
        "))\n",
        "\n",
        "results = []\n",
        "\n",
        "print(f\"\\n🔍 Total combinations to test: {len(param_combinations)}\")\n",
        "\n",
        "for i, (lr, batch_size, epochs, wd) in enumerate(param_combinations, 1):\n",
        "    print(f\"\\n🚀 Running Grid Search Trial {i}/{len(param_combinations)}\")\n",
        "    print(f\"🎯 Params: LR={lr}, Batch={batch_size}, Epochs={epochs}, Weight Decay={wd}\")\n",
        "\n",
        "    # Reload model each iteration\n",
        "    num_labels = len(label_mapping)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
        "\n",
        "    # Freeze lower layers for faster training\n",
        "    for name, param in model.named_parameters():\n",
        "        if not name.startswith(\"classifier\") and not name.startswith(\"bert.encoder.layer.11\"):\n",
        "            param.requires_grad = False\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./grid_results_trial_{i}\",\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"no\", # Changed from evaluation_strategy\n",
        "        learning_rate=lr,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        num_train_epochs=epochs,\n",
        "        weight_decay=wd,\n",
        "        logging_dir=\"./logs\",\n",
        "        logging_steps=10,\n",
        "        load_best_model_at_end=False,\n",
        "        metric_for_best_model=\"f1\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    metrics = trainer.evaluate()\n",
        "\n",
        "    result_entry = {\n",
        "        \"trial\": i,\n",
        "        \"learning_rate\": lr,\n",
        "        \"per_device_train_batch_size\": batch_size,\n",
        "        \"num_train_epochs\": epochs,\n",
        "        \"weight_decay\": wd,\n",
        "        \"accuracy\": metrics.get(\"eval_accuracy\", 0),\n",
        "        \"precision\": metrics.get(\"eval_precision\", 0),\n",
        "        \"recall\": metrics.get(\"eval_recall\", 0),\n",
        "        \"f1\": metrics.get(\"eval_f1\", 0)\n",
        "    }\n",
        "\n",
        "    results.append(result_entry)\n",
        "\n",
        "# Save results to Excel\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_excel(\"GridSearch_Results.xlsx\", index=False)\n",
        "print(\"\\n✅ Grid Search complete! Results saved to GridSearch_Results.xlsx\")\n",
        "\n",
        "# ===============================\n",
        "# 6️⃣ BEST MODEL SELECTION\n",
        "# ===============================\n",
        "\n",
        "best_trial = max(results, key=lambda x: x[\"f1\"])\n",
        "print(\"\\n🏆 Best Grid Search Configuration:\")\n",
        "for k, v in best_trial.items():\n",
        "    print(f\"{k}: {v}\")\n",
        "\n",
        "print(\"\\n✅ Complete\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "✅ Label mapping: {0: 'Normal', 1: 'Suicidal'}\n\n🔍 Total combinations to test: 8\n\n🚀 Running Grid Search Trial 1/8\n🎯 Params: LR=3e-05, Batch=8, Epochs=3, Weight Decay=0.01\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at mental/mental-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/tmp/ipython-input-4033805790.py:134: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='8100' max='8100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [8100/8100 07:57, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.081500</td>\n      <td>0.099013</td>\n      <td>0.971661</td>\n      <td>0.971664</td>\n      <td>0.971661</td>\n      <td>0.971662</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.071100</td>\n      <td>0.084789</td>\n      <td>0.975736</td>\n      <td>0.975734</td>\n      <td>0.975736</td>\n      <td>0.975713</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.093800</td>\n      <td>0.086624</td>\n      <td>0.976848</td>\n      <td>0.976842</td>\n      <td>0.976848</td>\n      <td>0.976829</td>\n    </tr>\n  </tbody>\n</table><p>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [675/675 00:24]\n    </div>\n    ",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n🚀 Running Grid Search Trial 2/8\n🎯 Params: LR=3e-05, Batch=8, Epochs=4, Weight Decay=0.01\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at mental/mental-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/tmp/ipython-input-4033805790.py:134: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='10800' max='10800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10800/10800 08:58, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.099200</td>\n      <td>0.097917</td>\n      <td>0.973514</td>\n      <td>0.973503</td>\n      <td>0.973514</td>\n      <td>0.973507</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.050800</td>\n      <td>0.082761</td>\n      <td>0.975921</td>\n      <td>0.975918</td>\n      <td>0.975921</td>\n      <td>0.975900</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.137400</td>\n      <td>0.087715</td>\n      <td>0.977033</td>\n      <td>0.977041</td>\n      <td>0.977033</td>\n      <td>0.977036</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.026100</td>\n      <td>0.086383</td>\n      <td>0.978515</td>\n      <td>0.978507</td>\n      <td>0.978515</td>\n      <td>0.978502</td>\n    </tr>\n  </tbody>\n</table><p>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [675/675 00:22]\n    </div>\n    ",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n🚀 Running Grid Search Trial 3/8\n🎯 Params: LR=3e-05, Batch=16, Epochs=3, Weight Decay=0.01\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at mental/mental-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/tmp/ipython-input-4033805790.py:134: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='4050' max='4050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4050/4050 06:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.127700</td>\n      <td>0.087276</td>\n      <td>0.970180</td>\n      <td>0.970166</td>\n      <td>0.970180</td>\n      <td>0.970151</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.082900</td>\n      <td>0.077469</td>\n      <td>0.974810</td>\n      <td>0.974798</td>\n      <td>0.974810</td>\n      <td>0.974795</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.080100</td>\n      <td>0.078211</td>\n      <td>0.975551</td>\n      <td>0.975539</td>\n      <td>0.975551</td>\n      <td>0.975536</td>\n    </tr>\n  </tbody>\n</table><p>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='338' max='338' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [338/338 00:20]\n    </div>\n    ",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n🚀 Running Grid Search Trial 4/8\n🎯 Params: LR=3e-05, Batch=16, Epochs=4, Weight Decay=0.01\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at mental/mental-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/tmp/ipython-input-4033805790.py:134: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='5400' max='5400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5400/5400 08:02, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.115100</td>\n      <td>0.087445</td>\n      <td>0.971106</td>\n      <td>0.971090</td>\n      <td>0.971106</td>\n      <td>0.971084</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.078700</td>\n      <td>0.076366</td>\n      <td>0.974995</td>\n      <td>0.974983</td>\n      <td>0.974995</td>\n      <td>0.974983</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.058900</td>\n      <td>0.080569</td>\n      <td>0.974995</td>\n      <td>0.975084</td>\n      <td>0.974995</td>\n      <td>0.975018</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.111200</td>\n      <td>0.075545</td>\n      <td>0.977403</td>\n      <td>0.977397</td>\n      <td>0.977403</td>\n      <td>0.977386</td>\n    </tr>\n  </tbody>\n</table><p>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='338' max='338' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [338/338 00:20]\n    </div>\n    ",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n🚀 Running Grid Search Trial 5/8\n🎯 Params: LR=5e-05, Batch=8, Epochs=3, Weight Decay=0.01\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at mental/mental-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/tmp/ipython-input-4033805790.py:134: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='8100' max='8100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [8100/8100 06:40, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.079000</td>\n      <td>0.097286</td>\n      <td>0.973884</td>\n      <td>0.973890</td>\n      <td>0.973884</td>\n      <td>0.973887</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.028400</td>\n      <td>0.077349</td>\n      <td>0.977774</td>\n      <td>0.977773</td>\n      <td>0.977774</td>\n      <td>0.977753</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.090900</td>\n      <td>0.081685</td>\n      <td>0.979811</td>\n      <td>0.979805</td>\n      <td>0.979811</td>\n      <td>0.979798</td>\n    </tr>\n  </tbody>\n</table><p>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [675/675 00:22]\n    </div>\n    ",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n🚀 Running Grid Search Trial 6/8\n🎯 Params: LR=5e-05, Batch=8, Epochs=4, Weight Decay=0.01\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at mental/mental-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/tmp/ipython-input-4033805790.py:134: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='10800' max='10800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10800/10800 08:53, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.070900</td>\n      <td>0.096014</td>\n      <td>0.974440</td>\n      <td>0.974433</td>\n      <td>0.974440</td>\n      <td>0.974436</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.041400</td>\n      <td>0.075271</td>\n      <td>0.977959</td>\n      <td>0.978007</td>\n      <td>0.977959</td>\n      <td>0.977924</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.133000</td>\n      <td>0.080154</td>\n      <td>0.980737</td>\n      <td>0.980730</td>\n      <td>0.980737</td>\n      <td>0.980730</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.007200</td>\n      <td>0.080827</td>\n      <td>0.981293</td>\n      <td>0.981291</td>\n      <td>0.981293</td>\n      <td>0.981279</td>\n    </tr>\n  </tbody>\n</table><p>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [675/675 00:22]\n    </div>\n    ",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n🚀 Running Grid Search Trial 7/8\n🎯 Params: LR=5e-05, Batch=16, Epochs=3, Weight Decay=0.01\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at mental/mental-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/tmp/ipython-input-4033805790.py:134: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='4050' max='4050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4050/4050 06:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.126200</td>\n      <td>0.082254</td>\n      <td>0.972588</td>\n      <td>0.972587</td>\n      <td>0.972588</td>\n      <td>0.972556</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.079500</td>\n      <td>0.069258</td>\n      <td>0.977033</td>\n      <td>0.977023</td>\n      <td>0.977033</td>\n      <td>0.977019</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.061700</td>\n      <td>0.070030</td>\n      <td>0.979255</td>\n      <td>0.979252</td>\n      <td>0.979255</td>\n      <td>0.979240</td>\n    </tr>\n  </tbody>\n</table><p>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='338' max='338' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [338/338 00:20]\n    </div>\n    ",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n🚀 Running Grid Search Trial 8/8\n🎯 Params: LR=5e-05, Batch=16, Epochs=4, Weight Decay=0.01\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at mental/mental-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/tmp/ipython-input-4033805790.py:134: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='5400' max='5400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5400/5400 08:00, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.102700</td>\n      <td>0.082515</td>\n      <td>0.972588</td>\n      <td>0.972572</td>\n      <td>0.972588</td>\n      <td>0.972573</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.070600</td>\n      <td>0.069187</td>\n      <td>0.977588</td>\n      <td>0.977579</td>\n      <td>0.977588</td>\n      <td>0.977576</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.041700</td>\n      <td>0.071709</td>\n      <td>0.978329</td>\n      <td>0.978384</td>\n      <td>0.978329</td>\n      <td>0.978344</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.080500</td>\n      <td>0.068425</td>\n      <td>0.980737</td>\n      <td>0.980746</td>\n      <td>0.980737</td>\n      <td>0.980718</td>\n    </tr>\n  </tbody>\n</table><p>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "\n    <div>\n      \n      <progress value='243' max='338' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [243/338 00:14 < 00:05, 16.26 it/s]\n    </div>\n    ",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='338' max='338' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [338/338 00:20]\n    </div>\n    "
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n✅ Grid Search complete! Results saved to GridSearch_Results.xlsx\n\n🏆 Best Grid Search Configuration:\ntrial: 6\nlearning_rate: 5e-05\nper_device_train_batch_size: 8\nnum_train_epochs: 4\nweight_decay: 0.01\naccuracy: 0.981292832005927\nprecision: 0.9812912739247692\nrecall: 0.981292832005927\nf1: 0.9812794158918405\n\n✅ Complete\n"
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4nTwHlBBx-nu",
        "outputId": "91951659-7a93-4eac-93bc-7db7a6c0337e"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python",
      "language": "python",
      "display_name": "Pyolite (preview)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9b21a84ecfaf4138b644319dc21c815d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_name": "PasswordModel",
            "_model_module": "@jupyter-widgets/controls",
            "_view_name": "PasswordView",
            "_view_module": "@jupyter-widgets/controls",
            "_dom_classes": [],
            "layout": "IPY_MODEL_0a8ee3d23c744962a67cda6f0a63a8b7",
            "value": "",
            "style": "IPY_MODEL_8cfd452b9e704a8fb557bfaf04cf4d2b",
            "placeholder": "​",
            "_view_count": null,
            "continuous_update": true,
            "_model_module_version": "1.5.0",
            "disabled": false,
            "description": "Token:"
          }
        },
        "9634cb37856a407badb14c8b31713bfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_name": "CheckboxModel",
            "_model_module": "@jupyter-widgets/controls",
            "_view_name": "CheckboxView",
            "_view_module": "@jupyter-widgets/controls",
            "_dom_classes": [],
            "layout": "IPY_MODEL_ae3b88629af041c5b84b0d77351b107f",
            "indent": true,
            "value": true,
            "style": "IPY_MODEL_0a9cb0823c80462daa534d7352014a86",
            "_view_count": null,
            "_model_module_version": "1.5.0",
            "disabled": false,
            "description": "Add token as git credential?"
          }
        },
        "b4ab14eeec9c4183a683aa1a226ee8d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_name": "HTMLModel",
            "_model_module": "@jupyter-widgets/controls",
            "_view_name": "HTMLView",
            "_view_module": "@jupyter-widgets/controls",
            "_dom_classes": [],
            "layout": "IPY_MODEL_374831d385bf488fb296843cc7e9d388",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>",
            "style": "IPY_MODEL_bff0398c66834722b760f00d2942816f",
            "placeholder": "​",
            "_view_count": null,
            "_model_module_version": "1.5.0",
            "description": ""
          }
        },
        "b0decee1132c4c6d8846e6327d3a504f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_name": "LabelModel",
            "_model_module": "@jupyter-widgets/controls",
            "_view_name": "LabelView",
            "_view_module": "@jupyter-widgets/controls",
            "_dom_classes": [],
            "layout": "IPY_MODEL_afa7bdee976d4a429b55546873e7c1fb",
            "value": "Connecting...",
            "style": "IPY_MODEL_bc55f7d45f12480292ffd542aa7d1d9b",
            "placeholder": "​",
            "_view_count": null,
            "_model_module_version": "1.5.0",
            "description": ""
          }
        },
        "d787e4e0f89e4823bed5493840c2337f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "grid_row": null,
            "_model_module": "@jupyter-widgets/base",
            "overflow": null,
            "max_height": null,
            "display": null,
            "grid_auto_flow": null,
            "grid_template_rows": null,
            "align_self": null,
            "grid_auto_columns": null,
            "width": null,
            "grid_area": null,
            "align_items": null,
            "_view_name": "LayoutView",
            "left": null,
            "height": null,
            "_view_module": "@jupyter-widgets/base",
            "object_position": null,
            "justify_content": null,
            "bottom": null,
            "max_width": null,
            "border": null,
            "margin": null,
            "order": null,
            "grid_column": null,
            "grid_auto_rows": null,
            "padding": null,
            "grid_template_columns": null,
            "justify_items": null,
            "object_fit": null,
            "visibility": null,
            "_view_count": null,
            "flex_flow": null,
            "min_height": null,
            "top": null,
            "min_width": null,
            "flex": null,
            "_model_module_version": "1.2.0",
            "grid_template_areas": null,
            "overflow_x": null,
            "right": null,
            "overflow_y": null,
            "grid_gap": null,
            "align_content": null
          }
        },
        "ae3b88629af041c5b84b0d77351b107f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "grid_row": null,
            "_model_module": "@jupyter-widgets/base",
            "overflow": null,
            "max_height": null,
            "display": null,
            "grid_auto_flow": null,
            "grid_template_rows": null,
            "align_self": null,
            "grid_auto_columns": null,
            "width": null,
            "grid_area": null,
            "align_items": null,
            "_view_name": "LayoutView",
            "left": null,
            "height": null,
            "_view_module": "@jupyter-widgets/base",
            "object_position": null,
            "justify_content": null,
            "bottom": null,
            "max_width": null,
            "border": null,
            "margin": null,
            "order": null,
            "grid_column": null,
            "grid_auto_rows": null,
            "padding": null,
            "grid_template_columns": null,
            "justify_items": null,
            "object_fit": null,
            "visibility": null,
            "_view_count": null,
            "flex_flow": null,
            "min_height": null,
            "top": null,
            "min_width": null,
            "flex": null,
            "_model_module_version": "1.2.0",
            "grid_template_areas": null,
            "overflow_x": null,
            "right": null,
            "overflow_y": null,
            "grid_gap": null,
            "align_content": null
          }
        },
        "bc55f7d45f12480292ffd542aa7d1d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3589dc5fa9174974baae0018570409bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "grid_row": null,
            "_model_module": "@jupyter-widgets/base",
            "overflow": null,
            "max_height": null,
            "display": null,
            "grid_auto_flow": null,
            "grid_template_rows": null,
            "align_self": null,
            "grid_auto_columns": null,
            "width": null,
            "grid_area": null,
            "align_items": null,
            "_view_name": "LayoutView",
            "left": null,
            "height": null,
            "_view_module": "@jupyter-widgets/base",
            "object_position": null,
            "justify_content": null,
            "bottom": null,
            "max_width": null,
            "border": null,
            "margin": null,
            "order": null,
            "grid_column": null,
            "grid_auto_rows": null,
            "padding": null,
            "grid_template_columns": null,
            "justify_items": null,
            "object_fit": null,
            "visibility": null,
            "_view_count": null,
            "flex_flow": null,
            "min_height": null,
            "top": null,
            "min_width": null,
            "flex": null,
            "_model_module_version": "1.2.0",
            "grid_template_areas": null,
            "overflow_x": null,
            "right": null,
            "overflow_y": null,
            "grid_gap": null,
            "align_content": null
          }
        },
        "0a8ee3d23c744962a67cda6f0a63a8b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "grid_row": null,
            "_model_module": "@jupyter-widgets/base",
            "overflow": null,
            "max_height": null,
            "display": null,
            "grid_auto_flow": null,
            "grid_template_rows": null,
            "align_self": null,
            "grid_auto_columns": null,
            "width": null,
            "grid_area": null,
            "align_items": null,
            "_view_name": "LayoutView",
            "left": null,
            "height": null,
            "_view_module": "@jupyter-widgets/base",
            "object_position": null,
            "justify_content": null,
            "bottom": null,
            "max_width": null,
            "border": null,
            "margin": null,
            "order": null,
            "grid_column": null,
            "grid_auto_rows": null,
            "padding": null,
            "grid_template_columns": null,
            "justify_items": null,
            "object_fit": null,
            "visibility": null,
            "_view_count": null,
            "flex_flow": null,
            "min_height": null,
            "top": null,
            "min_width": null,
            "flex": null,
            "_model_module_version": "1.2.0",
            "grid_template_areas": null,
            "overflow_x": null,
            "right": null,
            "overflow_y": null,
            "grid_gap": null,
            "align_content": null
          }
        },
        "1db23a05ce5a4f1c8595ab564214c880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a9cb0823c80462daa534d7352014a86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fc67afc315c41698f1de75462f83033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "grid_row": null,
            "_model_module": "@jupyter-widgets/base",
            "overflow": null,
            "max_height": null,
            "display": "flex",
            "grid_auto_flow": null,
            "grid_template_rows": null,
            "align_self": null,
            "grid_auto_columns": null,
            "width": "50%",
            "grid_area": null,
            "align_items": "center",
            "_view_name": "LayoutView",
            "left": null,
            "height": null,
            "_view_module": "@jupyter-widgets/base",
            "object_position": null,
            "justify_content": null,
            "bottom": null,
            "max_width": null,
            "border": null,
            "margin": null,
            "order": null,
            "grid_column": null,
            "grid_auto_rows": null,
            "padding": null,
            "grid_template_columns": null,
            "justify_items": null,
            "object_fit": null,
            "visibility": null,
            "_view_count": null,
            "flex_flow": "column",
            "min_height": null,
            "top": null,
            "min_width": null,
            "flex": null,
            "_model_module_version": "1.2.0",
            "grid_template_areas": null,
            "overflow_x": null,
            "right": null,
            "overflow_y": null,
            "grid_gap": null,
            "align_content": null
          }
        },
        "afa7bdee976d4a429b55546873e7c1fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "grid_row": null,
            "_model_module": "@jupyter-widgets/base",
            "overflow": null,
            "max_height": null,
            "display": null,
            "grid_auto_flow": null,
            "grid_template_rows": null,
            "align_self": null,
            "grid_auto_columns": null,
            "width": null,
            "grid_area": null,
            "align_items": null,
            "_view_name": "LayoutView",
            "left": null,
            "height": null,
            "_view_module": "@jupyter-widgets/base",
            "object_position": null,
            "justify_content": null,
            "bottom": null,
            "max_width": null,
            "border": null,
            "margin": null,
            "order": null,
            "grid_column": null,
            "grid_auto_rows": null,
            "padding": null,
            "grid_template_columns": null,
            "justify_items": null,
            "object_fit": null,
            "visibility": null,
            "_view_count": null,
            "flex_flow": null,
            "min_height": null,
            "top": null,
            "min_width": null,
            "flex": null,
            "_model_module_version": "1.2.0",
            "grid_template_areas": null,
            "overflow_x": null,
            "right": null,
            "overflow_y": null,
            "grid_gap": null,
            "align_content": null
          }
        },
        "a1b2cbe8b318475092b6d00988dcf377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_model_module": "@jupyter-widgets/controls",
            "tooltip": "",
            "button_style": "",
            "_view_name": "ButtonView",
            "_view_module": "@jupyter-widgets/controls",
            "_dom_classes": [],
            "layout": "IPY_MODEL_3589dc5fa9174974baae0018570409bd",
            "style": "IPY_MODEL_3ea00024dc0e47a5b4a8111fc377d4c0",
            "_view_count": null,
            "icon": "",
            "_model_module_version": "1.5.0",
            "disabled": false,
            "description": "Login"
          }
        },
        "bff0398c66834722b760f00d2942816f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "374831d385bf488fb296843cc7e9d388": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "grid_row": null,
            "_model_module": "@jupyter-widgets/base",
            "overflow": null,
            "max_height": null,
            "display": null,
            "grid_auto_flow": null,
            "grid_template_rows": null,
            "align_self": null,
            "grid_auto_columns": null,
            "width": null,
            "grid_area": null,
            "align_items": null,
            "_view_name": "LayoutView",
            "left": null,
            "height": null,
            "_view_module": "@jupyter-widgets/base",
            "object_position": null,
            "justify_content": null,
            "bottom": null,
            "max_width": null,
            "border": null,
            "margin": null,
            "order": null,
            "grid_column": null,
            "grid_auto_rows": null,
            "padding": null,
            "grid_template_columns": null,
            "justify_items": null,
            "object_fit": null,
            "visibility": null,
            "_view_count": null,
            "flex_flow": null,
            "min_height": null,
            "top": null,
            "min_width": null,
            "flex": null,
            "_model_module_version": "1.2.0",
            "grid_template_areas": null,
            "overflow_x": null,
            "right": null,
            "overflow_y": null,
            "grid_gap": null,
            "align_content": null
          }
        },
        "3ea00024dc0e47a5b4a8111fc377d4c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_module_version": "1.2.0",
            "_model_name": "ButtonStyleModel",
            "_model_module": "@jupyter-widgets/controls",
            "_view_name": "StyleView",
            "_view_module": "@jupyter-widgets/base",
            "font_weight": "",
            "_view_count": null,
            "button_color": null,
            "_model_module_version": "1.5.0"
          }
        },
        "19f17f40eac842faa992787373efa51d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_model_module": "@jupyter-widgets/controls",
            "_view_name": "VBoxView",
            "_view_module": "@jupyter-widgets/controls",
            "_dom_classes": [],
            "layout": "IPY_MODEL_7fc67afc315c41698f1de75462f83033",
            "_view_count": null,
            "_model_module_version": "1.5.0",
            "box_style": "",
            "children": []
          }
        },
        "7cb119d94756496d90e49cc4b77dd8d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_name": "HTMLModel",
            "_model_module": "@jupyter-widgets/controls",
            "_view_name": "HTMLView",
            "_view_module": "@jupyter-widgets/controls",
            "_dom_classes": [],
            "layout": "IPY_MODEL_d787e4e0f89e4823bed5493840c2337f",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>",
            "style": "IPY_MODEL_1db23a05ce5a4f1c8595ab564214c880",
            "placeholder": "​",
            "_view_count": null,
            "_model_module_version": "1.5.0",
            "description": ""
          }
        },
        "8cfd452b9e704a8fb557bfaf04cf4d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "kernel_info": {
      "name": "python"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}